created virtual environment CPython3.11.5.final.0-64 in 528ms
  creator CPython3Posix(dest=/localscratch/alexort.47185044.0/env, clear=False, no_vcs_ignore=False, global=False)
  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/home/alexort/.local/share/virtualenv)
    added seed packages: pip==23.2.1, setuptools==68.0.0, wheel==0.41.1
  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator
Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/einops-0.8.1+computecanada-py3-none-any.whl (from -r requirements.txt (line 1))
Requirement already satisfied: numpy==2.2.2+computecanada in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (2.2.2+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/PyYAML-6.0.2+computecanada-cp311-cp311-linux_x86_64.whl (from -r requirements.txt (line 3))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/scikit_learn-1.6.1+computecanada-cp311-cp311-linux_x86_64.whl (from -r requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/torch-2.7.1+computecanada-cp311-cp311-linux_x86_64.whl (from -r requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/tqdm-4.67.1+computecanada-py3-none-any.whl (from -r requirements.txt (line 6))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/wandb-0.19.6+computecanada-py3-none-linux_x86_64.whl (from -r requirements.txt (line 7))
Requirement already satisfied: scipy>=1.6.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from scikit_learn==1.6.1+computecanada->-r requirements.txt (line 4)) (1.15.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/joblib-1.5.1+computecanada-py3-none-any.whl (from scikit_learn==1.6.1+computecanada->-r requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/threadpoolctl-3.6.0+computecanada-py3-none-any.whl (from scikit_learn==1.6.1+computecanada->-r requirements.txt (line 4))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/filelock-3.18.0+computecanada-py3-none-any.whl (from torch==2.7.1->-r requirements.txt (line 5))
Requirement already satisfied: typing-extensions>=4.10.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/ipykernel/2025a/lib/python3.11/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (4.12.2+computecanada)
Requirement already satisfied: sympy>=1.13.3 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from torch==2.7.1->-r requirements.txt (line 5)) (1.13.3+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/networkx-3.5+computecanada-py3-none-any.whl (from torch==2.7.1->-r requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/jinja2-3.1.6+computecanada-py3-none-any.whl (from torch==2.7.1->-r requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/fsspec-2025.7.0+computecanada-py3-none-any.whl (from torch==2.7.1->-r requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/click-8.2.1+computecanada-py3-none-any.whl (from wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/docker_pycreds-0.4.0+computecanada-py2.py3-none-any.whl (from wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitpython-3.1.45+computecanada-py3-none-any.whl (from wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Requirement already satisfied: platformdirs in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/ipykernel/2025a/lib/python3.11/site-packages (from wandb==0.19.6+computecanada->-r requirements.txt (line 7)) (3.10.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3/protobuf-5.29.5+computecanada-cp311-cp311-linux_x86_64.whl (from wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Requirement already satisfied: psutil>=5.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/ipykernel/2025a/lib/python3.11/site-packages (from wandb==0.19.6+computecanada->-r requirements.txt (line 7)) (6.1.1+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pydantic-2.11.7+computecanada-py3-none-any.whl (from wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/requests-2.32.4+computecanada-py3-none-any.whl (from wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/sentry_sdk-2.33.2+computecanada-py2.py3-none-any.whl (from wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/setproctitle-1.3.4+computecanada-cp311-cp311-linux_x86_64.whl (from wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Requirement already satisfied: setuptools in /localscratch/alexort.47185044.0/env/lib/python3.11/site-packages (from wandb==0.19.6+computecanada->-r requirements.txt (line 7)) (68.0.0)
Requirement already satisfied: six>=1.4.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from docker-pycreds>=0.4.0->wandb==0.19.6+computecanada->-r requirements.txt (line 7)) (1.17.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/gitdb-4.0.12+computecanada-py3-none-any.whl (from gitpython!=3.1.29,>=1.0.0->wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/annotated_types-0.7.0+computecanada-py3-none-any.whl (from pydantic<3,>=2.6->wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic/pydantic_core-2.33.2+computecanada-cp311-cp311-linux_x86_64.whl (from pydantic<3,>=2.6->wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/typing_inspection-0.4.1+computecanada-py3-none-any.whl (from pydantic<3,>=2.6->wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/charset_normalizer-3.4.2+computecanada-py3-none-any.whl (from requests<3,>=2.0.0->wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/idna-3.10+computecanada-py3-none-any.whl (from requests<3,>=2.0.0->wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/urllib3-2.5.0+computecanada-py3-none-any.whl (from requests<3,>=2.0.0->wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/certifi-2025.7.14+computecanada-py3-none-any.whl (from requests<3,>=2.0.0->wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2025a/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.7.1->-r requirements.txt (line 5)) (1.3.0+computecanada)
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/MarkupSafe-2.1.5+computecanada-cp311-cp311-linux_x86_64.whl (from jinja2->torch==2.7.1->-r requirements.txt (line 5))
Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/smmap-5.0.2+computecanada-py3-none-any.whl (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb==0.19.6+computecanada->-r requirements.txt (line 7))
Installing collected packages: urllib3, typing-inspection, tqdm, threadpoolctl, smmap, setproctitle, PyYAML, pydantic-core, protobuf, networkx, MarkupSafe, joblib, idna, fsspec, filelock, einops, docker-pycreds, click, charset-normalizer, certifi, annotated-types, sentry-sdk, scikit_learn, requests, pydantic, jinja2, gitdb, torch, gitpython, wandb
Successfully installed MarkupSafe-2.1.5+computecanada PyYAML-6.0.2+computecanada annotated-types-0.7.0+computecanada certifi-2025.7.14+computecanada charset-normalizer-3.4.2+computecanada click-8.2.1+computecanada docker-pycreds-0.4.0+computecanada einops-0.8.1+computecanada filelock-3.18.0+computecanada fsspec-2025.7.0+computecanada gitdb-4.0.12+computecanada gitpython-3.1.45+computecanada idna-3.10+computecanada jinja2-3.1.6+computecanada joblib-1.5.1+computecanada networkx-3.5+computecanada protobuf-5.29.5+computecanada pydantic-2.11.7+computecanada pydantic-core-2.33.2+computecanada requests-2.32.4+computecanada scikit_learn-1.6.1+computecanada sentry-sdk-2.33.2+computecanada setproctitle-1.3.4+computecanada smmap-5.0.2+computecanada threadpoolctl-3.6.0+computecanada torch-2.7.1+computecanada tqdm-4.67.1+computecanada typing-inspection-0.4.1+computecanada urllib3-2.5.0+computecanada wandb-0.19.6+computecanada
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Tracking run with wandb version 0.19.6
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
Training:   0%|          | 0/3000 [00:00<?, ?epoch/s]Training:   0%|          | 0/3000 [00:00<?, ?epoch/s, Training loss (per batch)=0.16]Training:   0%|          | 1/3000 [00:00<49:39,  1.01epoch/s, Training loss (per batch)=0.16]Training:   0%|          | 1/3000 [00:01<49:39,  1.01epoch/s, Training loss (per batch)=0.08]Training:   0%|          | 2/3000 [00:01<37:52,  1.32epoch/s, Training loss (per batch)=0.08]Training:   0%|          | 2/3000 [00:02<37:52,  1.32epoch/s, Training loss (per batch)=0.08]Training:   0%|          | 3/3000 [00:02<35:07,  1.42epoch/s, Training loss (per batch)=0.08]Training:   0%|          | 3/3000 [00:02<35:07,  1.42epoch/s, Training loss (per batch)=0.09]Training:   0%|          | 4/3000 [00:02<33:04,  1.51epoch/s, Training loss (per batch)=0.09]Training:   0%|          | 4/3000 [00:03<33:04,  1.51epoch/s, Training loss (per batch)=0.22]Training:   0%|          | 5/3000 [00:03<32:09,  1.55epoch/s, Training loss (per batch)=0.22]Training:   0%|          | 5/3000 [00:04<32:09,  1.55epoch/s, Training loss (per batch)=0.18]Training:   0%|          | 6/3000 [00:04<31:10,  1.60epoch/s, Training loss (per batch)=0.18]Training:   0%|          | 6/3000 [00:04<31:10,  1.60epoch/s, Training loss (per batch)=0.15]Training:   0%|          | 7/3000 [00:04<31:06,  1.60epoch/s, Training loss (per batch)=0.15]Training:   0%|          | 7/3000 [00:05<31:06,  1.60epoch/s, Training loss (per batch)=0.60]Training:   0%|          | 8/3000 [00:05<31:09,  1.60epoch/s, Training loss (per batch)=0.60]Training:   0%|          | 8/3000 [00:05<31:09,  1.60epoch/s, Training loss (per batch)=0.20]Training:   0%|          | 9/3000 [00:05<30:44,  1.62epoch/s, Training loss (per batch)=0.20]Training:   0%|          | 9/3000 [00:06<30:44,  1.62epoch/s, Training loss (per batch)=0.07]Training:   0%|          | 10/3000 [00:06<30:45,  1.62epoch/s, Training loss (per batch)=0.07]Training:   0%|          | 10/3000 [00:07<30:45,  1.62epoch/s, Training loss (per batch)=0.58]Training:   0%|          | 11/3000 [00:07<30:14,  1.65epoch/s, Training loss (per batch)=0.58]Training:   0%|          | 11/3000 [00:07<30:14,  1.65epoch/s, Training loss (per batch)=0.54]Training:   0%|          | 12/3000 [00:07<30:27,  1.64epoch/s, Training loss (per batch)=0.54]Training:   0%|          | 12/3000 [00:08<30:27,  1.64epoch/s, Training loss (per batch)=0.16]Training:   0%|          | 13/3000 [00:08<30:49,  1.62epoch/s, Training loss (per batch)=0.16]Training:   0%|          | 13/3000 [00:08<30:49,  1.62epoch/s, Training loss (per batch)=0.20]Training:   0%|          | 14/3000 [00:08<30:22,  1.64epoch/s, Training loss (per batch)=0.20]Training:   0%|          | 14/3000 [00:09<30:22,  1.64epoch/s, Training loss (per batch)=0.25]Training:   0%|          | 15/3000 [00:09<29:43,  1.67epoch/s, Training loss (per batch)=0.25]Training:   0%|          | 15/3000 [00:10<29:43,  1.67epoch/s, Training loss (per batch)=0.29]Training:   1%|          | 16/3000 [00:10<29:53,  1.66epoch/s, Training loss (per batch)=0.29]Training:   1%|          | 16/3000 [00:10<29:53,  1.66epoch/s, Training loss (per batch)=0.43]Training:   1%|          | 17/3000 [00:10<30:13,  1.64epoch/s, Training loss (per batch)=0.43]Training:   1%|          | 17/3000 [00:11<30:13,  1.64epoch/s, Training loss (per batch)=0.33]Training:   1%|          | 18/3000 [00:11<30:05,  1.65epoch/s, Training loss (per batch)=0.33]Training:   1%|          | 18/3000 [00:11<30:05,  1.65epoch/s, Training loss (per batch)=0.28]Training:   1%|          | 19/3000 [00:11<30:23,  1.63epoch/s, Training loss (per batch)=0.28]Training:   1%|          | 19/3000 [00:12<30:23,  1.63epoch/s, Training loss (per batch)=0.26]Training:   1%|          | 20/3000 [00:12<30:27,  1.63epoch/s, Training loss (per batch)=0.26]Training:   1%|          | 20/3000 [00:13<30:27,  1.63epoch/s, Training loss (per batch)=0.16]Training:   1%|          | 21/3000 [00:13<30:24,  1.63epoch/s, Training loss (per batch)=0.16]Training:   1%|          | 21/3000 [00:13<30:24,  1.63epoch/s, Training loss (per batch)=0.48]Training:   1%|          | 22/3000 [00:13<30:30,  1.63epoch/s, Training loss (per batch)=0.48]Training:   1%|          | 22/3000 [00:14<30:30,  1.63epoch/s, Training loss (per batch)=0.37]Training:   1%|          | 23/3000 [00:14<30:25,  1.63epoch/s, Training loss (per batch)=0.37]Training:   1%|          | 23/3000 [00:15<30:25,  1.63epoch/s, Training loss (per batch)=0.13]Training:   1%|          | 24/3000 [00:15<30:17,  1.64epoch/s, Training loss (per batch)=0.13]Training:   1%|          | 24/3000 [00:15<30:17,  1.64epoch/s, Training loss (per batch)=0.05]Training:   1%|          | 25/3000 [00:15<30:22,  1.63epoch/s, Training loss (per batch)=0.05]Training:   1%|          | 25/3000 [00:16<30:22,  1.63epoch/s, Training loss (per batch)=0.04]Training:   1%|          | 26/3000 [00:16<30:08,  1.64epoch/s, Training loss (per batch)=0.04]Training:   1%|          | 26/3000 [00:16<30:08,  1.64epoch/s, Training loss (per batch)=0.05]Training:   1%|          | 27/3000 [00:16<30:02,  1.65epoch/s, Training loss (per batch)=0.05]Training:   1%|          | 27/3000 [00:17<30:02,  1.65epoch/s, Training loss (per batch)=0.09]Training:   1%|          | 28/3000 [00:17<30:12,  1.64epoch/s, Training loss (per batch)=0.09]Training:   1%|          | 28/3000 [00:18<30:12,  1.64epoch/s, Training loss (per batch)=0.07]Training:   1%|          | 29/3000 [00:18<30:17,  1.63epoch/s, Training loss (per batch)=0.07]Training:   1%|          | 29/3000 [00:18<30:17,  1.63epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 30/3000 [00:18<29:58,  1.65epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 30/3000 [00:19<29:58,  1.65epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 31/3000 [00:19<29:59,  1.65epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 31/3000 [00:19<29:59,  1.65epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 32/3000 [00:19<29:26,  1.68epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 32/3000 [00:20<29:26,  1.68epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 33/3000 [00:20<29:41,  1.67epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 33/3000 [00:21<29:41,  1.67epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 34/3000 [00:21<29:43,  1.66epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 34/3000 [00:21<29:43,  1.66epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 35/3000 [00:21<29:57,  1.65epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 35/3000 [00:22<29:57,  1.65epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 36/3000 [00:22<29:55,  1.65epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 36/3000 [00:22<29:55,  1.65epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 37/3000 [00:22<29:56,  1.65epoch/s, Training loss (per batch)=0.03]Training:   1%|          | 37/3000 [00:23<29:56,  1.65epoch/s, Training loss (per batch)=0.04]Training:   1%|▏         | 38/3000 [00:23<29:27,  1.68epoch/s, Training loss (per batch)=0.04]Training:   1%|▏         | 38/3000 [00:24<29:27,  1.68epoch/s, Training loss (per batch)=0.04]Training:   1%|▏         | 39/3000 [00:24<29:13,  1.69epoch/s, Training loss (per batch)=0.04]Training:   1%|▏         | 39/3000 [00:24<29:13,  1.69epoch/s, Training loss (per batch)=0.04]Training:   1%|▏         | 40/3000 [00:24<29:06,  1.69epoch/s, Training loss (per batch)=0.04]Training:   1%|▏         | 40/3000 [00:25<29:06,  1.69epoch/s, Training loss (per batch)=0.06]Training:   1%|▏         | 41/3000 [00:25<29:26,  1.68epoch/s, Training loss (per batch)=0.06]Training:   1%|▏         | 41/3000 [00:25<29:26,  1.68epoch/s, Training loss (per batch)=0.05]Training:   1%|▏         | 42/3000 [00:25<29:29,  1.67epoch/s, Training loss (per batch)=0.05]Training:   1%|▏         | 42/3000 [00:26<29:29,  1.67epoch/s, Training loss (per batch)=0.03]Training:   1%|▏         | 43/3000 [00:26<29:31,  1.67epoch/s, Training loss (per batch)=0.03]Training:   1%|▏         | 43/3000 [00:27<29:31,  1.67epoch/s, Training loss (per batch)=0.03]Training:   1%|▏         | 44/3000 [00:27<29:25,  1.67epoch/s, Training loss (per batch)=0.03]Training:   1%|▏         | 44/3000 [00:27<29:25,  1.67epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 45/3000 [00:27<29:28,  1.67epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 45/3000 [00:28<29:28,  1.67epoch/s, Training loss (per batch)=0.10]Training:   2%|▏         | 46/3000 [00:28<29:12,  1.69epoch/s, Training loss (per batch)=0.10]Training:   2%|▏         | 46/3000 [00:28<29:12,  1.69epoch/s, Training loss (per batch)=0.07]Training:   2%|▏         | 47/3000 [00:28<29:22,  1.68epoch/s, Training loss (per batch)=0.07]Training:   2%|▏         | 47/3000 [00:29<29:22,  1.68epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 48/3000 [00:29<29:17,  1.68epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 48/3000 [00:29<29:17,  1.68epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 49/3000 [00:29<29:00,  1.70epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 49/3000 [00:30<29:00,  1.70epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 50/3000 [00:30<29:56,  1.64epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 50/3000 [00:31<29:56,  1.64epoch/s, Training loss (per batch)=0.06]Training:   2%|▏         | 51/3000 [00:31<29:40,  1.66epoch/s, Training loss (per batch)=0.06]Training:   2%|▏         | 51/3000 [00:31<29:40,  1.66epoch/s, Training loss (per batch)=0.07]Training:   2%|▏         | 52/3000 [00:31<29:36,  1.66epoch/s, Training loss (per batch)=0.07]Training:   2%|▏         | 52/3000 [00:32<29:36,  1.66epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 53/3000 [00:32<29:57,  1.64epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 53/3000 [00:33<29:57,  1.64epoch/s, Training loss (per batch)=0.04]Training:   2%|▏         | 54/3000 [00:33<29:44,  1.65epoch/s, Training loss (per batch)=0.04]Training:   2%|▏         | 54/3000 [00:33<29:44,  1.65epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 55/3000 [00:33<29:59,  1.64epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 55/3000 [00:34<29:59,  1.64epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 56/3000 [00:34<29:44,  1.65epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 56/3000 [00:34<29:44,  1.65epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 57/3000 [00:34<29:25,  1.67epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 57/3000 [00:35<29:25,  1.67epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 58/3000 [00:35<29:08,  1.68epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 58/3000 [00:36<29:08,  1.68epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 59/3000 [00:36<29:26,  1.67epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 59/3000 [00:36<29:26,  1.67epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 60/3000 [00:36<29:19,  1.67epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 60/3000 [00:37<29:19,  1.67epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 61/3000 [00:37<29:20,  1.67epoch/s, Training loss (per batch)=0.05]Training:   2%|▏         | 61/3000 [00:37<29:20,  1.67epoch/s, Training loss (per batch)=0.04]Training:   2%|▏         | 62/3000 [00:37<29:16,  1.67epoch/s, Training loss (per batch)=0.04]Training:   2%|▏         | 62/3000 [00:38<29:16,  1.67epoch/s, Training loss (per batch)=0.03]Training:   2%|▏         | 63/3000 [00:38<29:38,  1.65epoch/s, Training loss (per batch)=0.03]Training:   2%|▏         | 63/3000 [00:39<29:38,  1.65epoch/s, Training loss (per batch)=0.03]Training:   2%|▏         | 64/3000 [00:39<29:44,  1.65epoch/s, Training loss (per batch)=0.03]Training:   2%|▏         | 64/3000 [00:39<29:44,  1.65epoch/s, Training loss (per batch)=0.03]Training:   2%|▏         | 65/3000 [00:39<29:45,  1.64epoch/s, Training loss (per batch)=0.03]Training:   2%|▏         | 65/3000 [00:40<29:45,  1.64epoch/s, Training loss (per batch)=0.03]Training:   2%|▏         | 66/3000 [00:40<29:34,  1.65epoch/s, Training loss (per batch)=0.03]Training:   2%|▏         | 66/3000 [00:40<29:34,  1.65epoch/s, Training loss (per batch)=0.03]Training:   2%|▏         | 67/3000 [00:40<29:29,  1.66epoch/s, Training loss (per batch)=0.03]Training:   2%|▏         | 67/3000 [00:41<29:29,  1.66epoch/s, Training loss (per batch)=0.02]Training:   2%|▏         | 68/3000 [00:41<29:17,  1.67epoch/s, Training loss (per batch)=0.02]Training:   2%|▏         | 68/3000 [00:42<29:17,  1.67epoch/s, Training loss (per batch)=0.02]Training:   2%|▏         | 69/3000 [00:42<29:36,  1.65epoch/s, Training loss (per batch)=0.02]Training:   2%|▏         | 69/3000 [00:42<29:36,  1.65epoch/s, Training loss (per batch)=0.02]Training:   2%|▏         | 70/3000 [00:42<29:29,  1.66epoch/s, Training loss (per batch)=0.02]Training:   2%|▏         | 70/3000 [00:43<29:29,  1.66epoch/s, Training loss (per batch)=0.02]Training:   2%|▏         | 71/3000 [00:43<29:30,  1.65epoch/s, Training loss (per batch)=0.02]Training:   2%|▏         | 71/3000 [00:43<29:30,  1.65epoch/s, Training loss (per batch)=0.02]Training:   2%|▏         | 72/3000 [00:43<29:53,  1.63epoch/s, Training loss (per batch)=0.02]Training:   2%|▏         | 72/3000 [00:44<29:53,  1.63epoch/s, Training loss (per batch)=0.02]Training:   2%|▏         | 73/3000 [00:44<29:33,  1.65epoch/s, Training loss (per batch)=0.02]Training:   2%|▏         | 73/3000 [00:45<29:33,  1.65epoch/s, Training loss (per batch)=0.02]Training:   2%|▏         | 74/3000 [00:45<29:21,  1.66epoch/s, Training loss (per batch)=0.02]Training:   2%|▏         | 74/3000 [00:45<29:21,  1.66epoch/s, Training loss (per batch)=0.02]Training:   2%|▎         | 75/3000 [00:45<29:12,  1.67epoch/s, Training loss (per batch)=0.02]Training:   2%|▎         | 75/3000 [00:46<29:12,  1.67epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 76/3000 [00:46<29:14,  1.67epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 76/3000 [00:46<29:14,  1.67epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 77/3000 [00:46<28:47,  1.69epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 77/3000 [00:47<28:47,  1.69epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 78/3000 [00:47<29:03,  1.68epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 78/3000 [00:48<29:03,  1.68epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 79/3000 [00:48<29:03,  1.68epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 79/3000 [00:48<29:03,  1.68epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 80/3000 [00:48<29:02,  1.68epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 80/3000 [00:49<29:02,  1.68epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 81/3000 [00:49<28:57,  1.68epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 81/3000 [00:49<28:57,  1.68epoch/s, Training loss (per batch)=0.03]Training:   3%|▎         | 82/3000 [00:49<28:55,  1.68epoch/s, Training loss (per batch)=0.03]Training:   3%|▎         | 82/3000 [00:50<28:55,  1.68epoch/s, Training loss (per batch)=0.04]Training:   3%|▎         | 83/3000 [00:50<28:52,  1.68epoch/s, Training loss (per batch)=0.04]Training:   3%|▎         | 83/3000 [00:51<28:52,  1.68epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 84/3000 [00:51<29:03,  1.67epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 84/3000 [00:51<29:03,  1.67epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 85/3000 [00:51<28:44,  1.69epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 85/3000 [00:52<28:44,  1.69epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 86/3000 [00:52<28:51,  1.68epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 86/3000 [00:52<28:51,  1.68epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 87/3000 [00:52<29:05,  1.67epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 87/3000 [00:53<29:05,  1.67epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 88/3000 [00:53<29:23,  1.65epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 88/3000 [00:54<29:23,  1.65epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 89/3000 [00:54<29:22,  1.65epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 89/3000 [00:54<29:22,  1.65epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 90/3000 [00:54<29:10,  1.66epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 90/3000 [00:55<29:10,  1.66epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 91/3000 [00:55<29:27,  1.65epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 91/3000 [00:55<29:27,  1.65epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 92/3000 [00:55<29:13,  1.66epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 92/3000 [00:56<29:13,  1.66epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 93/3000 [00:56<29:13,  1.66epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 93/3000 [00:57<29:13,  1.66epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 94/3000 [00:57<29:17,  1.65epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 94/3000 [00:57<29:17,  1.65epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 95/3000 [00:57<28:44,  1.68epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 95/3000 [00:58<28:44,  1.68epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 96/3000 [00:58<29:06,  1.66epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 96/3000 [00:58<29:06,  1.66epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 97/3000 [00:58<29:10,  1.66epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 97/3000 [00:59<29:10,  1.66epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 98/3000 [00:59<29:15,  1.65epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 98/3000 [01:00<29:15,  1.65epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 99/3000 [01:00<29:17,  1.65epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 99/3000 [01:00<29:17,  1.65epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 100/3000 [01:00<29:23,  1.64epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 100/3000 [01:01<29:23,  1.64epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 101/3000 [01:01<29:19,  1.65epoch/s, Training loss (per batch)=0.02]Training:   3%|▎         | 101/3000 [01:01<29:19,  1.65epoch/s, Training loss (per batch)=0.01]Training:   3%|▎         | 102/3000 [01:01<29:02,  1.66epoch/s, Training loss (per batch)=0.01]Training:   3%|▎         | 102/3000 [01:02<29:02,  1.66epoch/s, Training loss (per batch)=0.01]Training:   3%|▎         | 103/3000 [01:02<29:17,  1.65epoch/s, Training loss (per batch)=0.01]Training:   3%|▎         | 103/3000 [01:03<29:17,  1.65epoch/s, Training loss (per batch)=0.01]Training:   3%|▎         | 104/3000 [01:03<28:49,  1.67epoch/s, Training loss (per batch)=0.01]Training:   3%|▎         | 104/3000 [01:03<28:49,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 105/3000 [01:03<28:56,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 105/3000 [01:04<28:56,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 106/3000 [01:04<29:13,  1.65epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 106/3000 [01:04<29:13,  1.65epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 107/3000 [01:04<28:57,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 107/3000 [01:05<28:57,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 108/3000 [01:05<29:01,  1.66epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 108/3000 [01:06<29:01,  1.66epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 109/3000 [01:06<28:58,  1.66epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 109/3000 [01:06<28:58,  1.66epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 110/3000 [01:06<28:44,  1.68epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 110/3000 [01:07<28:44,  1.68epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 111/3000 [01:07<28:29,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 111/3000 [01:07<28:29,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 112/3000 [01:07<28:42,  1.68epoch/s, Training loss (per batch)=0.01]Training:   4%|▎         | 112/3000 [01:08<28:42,  1.68epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 113/3000 [01:08<28:51,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 113/3000 [01:09<28:51,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 114/3000 [01:09<28:50,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 114/3000 [01:09<28:50,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 115/3000 [01:09<28:31,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 115/3000 [01:10<28:31,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 116/3000 [01:10<28:31,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 116/3000 [01:10<28:31,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 117/3000 [01:10<28:46,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 117/3000 [01:11<28:46,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 118/3000 [01:11<28:20,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 118/3000 [01:12<28:20,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 119/3000 [01:12<28:22,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 119/3000 [01:12<28:22,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 120/3000 [01:12<28:19,  1.70epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 120/3000 [01:13<28:19,  1.70epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 121/3000 [01:13<28:31,  1.68epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 121/3000 [01:13<28:31,  1.68epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 122/3000 [01:13<28:18,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 122/3000 [01:14<28:18,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 123/3000 [01:14<28:38,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 123/3000 [01:15<28:38,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 124/3000 [01:15<28:24,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 124/3000 [01:15<28:24,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 125/3000 [01:15<27:56,  1.71epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 125/3000 [01:16<27:56,  1.71epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 126/3000 [01:16<28:06,  1.70epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 126/3000 [01:16<28:06,  1.70epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 127/3000 [01:16<28:16,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 127/3000 [01:17<28:16,  1.69epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 128/3000 [01:17<28:25,  1.68epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 128/3000 [01:17<28:25,  1.68epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 129/3000 [01:17<28:37,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 129/3000 [01:18<28:37,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 130/3000 [01:18<28:40,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 130/3000 [01:19<28:40,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 131/3000 [01:19<28:33,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 131/3000 [01:19<28:33,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 132/3000 [01:19<28:41,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 132/3000 [01:20<28:41,  1.67epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 133/3000 [01:20<29:06,  1.64epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 133/3000 [01:21<29:06,  1.64epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 134/3000 [01:21<29:21,  1.63epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 134/3000 [01:21<29:21,  1.63epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 135/3000 [01:21<30:01,  1.59epoch/s, Training loss (per batch)=0.01]Training:   4%|▍         | 135/3000 [01:22<30:01,  1.59epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 136/3000 [01:22<29:19,  1.63epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 136/3000 [01:22<29:19,  1.63epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 137/3000 [01:22<29:16,  1.63epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 137/3000 [01:23<29:16,  1.63epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 138/3000 [01:23<29:11,  1.63epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 138/3000 [01:24<29:11,  1.63epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 139/3000 [01:24<29:10,  1.63epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 139/3000 [01:24<29:10,  1.63epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 140/3000 [01:24<29:04,  1.64epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 140/3000 [01:25<29:04,  1.64epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 141/3000 [01:25<29:04,  1.64epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 141/3000 [01:25<29:04,  1.64epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 142/3000 [01:25<29:08,  1.63epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 142/3000 [01:26<29:08,  1.63epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 143/3000 [01:26<28:56,  1.65epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 143/3000 [01:27<28:56,  1.65epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 144/3000 [01:27<28:29,  1.67epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 144/3000 [01:27<28:29,  1.67epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 145/3000 [01:27<28:38,  1.66epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 145/3000 [01:28<28:38,  1.66epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 146/3000 [01:28<28:37,  1.66epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 146/3000 [01:28<28:37,  1.66epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 147/3000 [01:28<28:31,  1.67epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 147/3000 [01:29<28:31,  1.67epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 148/3000 [01:29<28:17,  1.68epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 148/3000 [01:30<28:17,  1.68epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 149/3000 [01:30<27:58,  1.70epoch/s, Training loss (per batch)=0.01]Training:   5%|▍         | 149/3000 [01:30<27:58,  1.70epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 150/3000 [01:30<28:29,  1.67epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 150/3000 [01:31<28:29,  1.67epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 151/3000 [01:31<28:35,  1.66epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 151/3000 [01:31<28:35,  1.66epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 152/3000 [01:31<28:29,  1.67epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 152/3000 [01:32<28:29,  1.67epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 153/3000 [01:32<28:40,  1.65epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 153/3000 [01:33<28:40,  1.65epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 154/3000 [01:33<28:21,  1.67epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 154/3000 [01:33<28:21,  1.67epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 155/3000 [01:33<28:13,  1.68epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 155/3000 [01:34<28:13,  1.68epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 156/3000 [01:34<28:12,  1.68epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 156/3000 [01:34<28:12,  1.68epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 157/3000 [01:34<28:13,  1.68epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 157/3000 [01:35<28:13,  1.68epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 158/3000 [01:35<28:26,  1.67epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 158/3000 [01:36<28:26,  1.67epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 159/3000 [01:36<28:26,  1.66epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 159/3000 [01:36<28:26,  1.66epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 160/3000 [01:36<28:02,  1.69epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 160/3000 [01:37<28:02,  1.69epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 161/3000 [01:37<27:55,  1.69epoch/s, Training loss (per batch)=0.01]Training:   5%|▌         | 161/3000 [01:37<27:55,  1.69epoch/s, Training loss (per batch)=0.04]Training:   5%|▌         | 162/3000 [01:37<28:10,  1.68epoch/s, Training loss (per batch)=0.04]Training:   5%|▌         | 162/3000 [01:38<28:10,  1.68epoch/s, Training loss (per batch)=0.03]Training:   5%|▌         | 163/3000 [01:38<28:16,  1.67epoch/s, Training loss (per batch)=0.03]Training:   5%|▌         | 163/3000 [01:39<28:16,  1.67epoch/s, Training loss (per batch)=0.02]Training:   5%|▌         | 164/3000 [01:39<28:15,  1.67epoch/s, Training loss (per batch)=0.02]Training:   5%|▌         | 164/3000 [01:39<28:15,  1.67epoch/s, Training loss (per batch)=0.02]Training:   6%|▌         | 165/3000 [01:39<28:02,  1.68epoch/s, Training loss (per batch)=0.02]Training:   6%|▌         | 165/3000 [01:40<28:02,  1.68epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 166/3000 [01:40<28:29,  1.66epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 166/3000 [01:40<28:29,  1.66epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 167/3000 [01:40<28:18,  1.67epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 167/3000 [01:41<28:18,  1.67epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 168/3000 [01:41<28:09,  1.68epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 168/3000 [01:42<28:09,  1.68epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 169/3000 [01:42<28:50,  1.64epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 169/3000 [01:42<28:50,  1.64epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 170/3000 [01:42<28:26,  1.66epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 170/3000 [01:43<28:26,  1.66epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 171/3000 [01:43<28:20,  1.66epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 171/3000 [01:43<28:20,  1.66epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 172/3000 [01:43<28:18,  1.67epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 172/3000 [01:44<28:18,  1.67epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 173/3000 [01:44<28:13,  1.67epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 173/3000 [01:45<28:13,  1.67epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 174/3000 [01:45<28:07,  1.68epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 174/3000 [01:45<28:07,  1.68epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 175/3000 [01:45<27:42,  1.70epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 175/3000 [01:46<27:42,  1.70epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 176/3000 [01:46<27:40,  1.70epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 176/3000 [01:46<27:40,  1.70epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 177/3000 [01:46<27:45,  1.69epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 177/3000 [01:47<27:45,  1.69epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 178/3000 [01:47<27:39,  1.70epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 178/3000 [01:48<27:39,  1.70epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 179/3000 [01:48<27:45,  1.69epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 179/3000 [01:48<27:45,  1.69epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 180/3000 [01:48<27:50,  1.69epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 180/3000 [01:49<27:50,  1.69epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 181/3000 [01:49<27:54,  1.68epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 181/3000 [01:49<27:54,  1.68epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 182/3000 [01:49<27:58,  1.68epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 182/3000 [01:50<27:58,  1.68epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 183/3000 [01:50<27:44,  1.69epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 183/3000 [01:50<27:44,  1.69epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 184/3000 [01:50<27:39,  1.70epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 184/3000 [01:51<27:39,  1.70epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 185/3000 [01:51<27:45,  1.69epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 185/3000 [01:52<27:45,  1.69epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 186/3000 [01:52<27:47,  1.69epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 186/3000 [01:52<27:47,  1.69epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 187/3000 [01:52<27:47,  1.69epoch/s, Training loss (per batch)=0.01]Training:   6%|▌         | 187/3000 [01:53<27:47,  1.69epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 188/3000 [01:53<28:14,  1.66epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 188/3000 [01:53<28:14,  1.66epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 189/3000 [01:53<28:00,  1.67epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 189/3000 [01:54<28:00,  1.67epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 190/3000 [01:54<27:57,  1.68epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 190/3000 [01:55<27:57,  1.68epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 191/3000 [01:55<27:49,  1.68epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 191/3000 [01:55<27:49,  1.68epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 192/3000 [01:55<27:32,  1.70epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 192/3000 [01:56<27:32,  1.70epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 193/3000 [01:56<27:26,  1.70epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 193/3000 [01:56<27:26,  1.70epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 194/3000 [01:56<27:14,  1.72epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 194/3000 [01:57<27:14,  1.72epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 195/3000 [01:57<27:30,  1.70epoch/s, Training loss (per batch)=0.01]Training:   6%|▋         | 195/3000 [01:58<27:30,  1.70epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 196/3000 [01:58<27:46,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 196/3000 [01:58<27:46,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 197/3000 [01:58<27:49,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 197/3000 [01:59<27:49,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 198/3000 [01:59<27:49,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 198/3000 [01:59<27:49,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 199/3000 [01:59<27:37,  1.69epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 199/3000 [02:00<27:37,  1.69epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 200/3000 [02:00<29:12,  1.60epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 200/3000 [02:01<29:12,  1.60epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 201/3000 [02:01<28:49,  1.62epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 201/3000 [02:01<28:49,  1.62epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 202/3000 [02:01<28:58,  1.61epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 202/3000 [02:02<28:58,  1.61epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 203/3000 [02:02<28:25,  1.64epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 203/3000 [02:02<28:25,  1.64epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 204/3000 [02:02<28:11,  1.65epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 204/3000 [02:03<28:11,  1.65epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 205/3000 [02:03<28:04,  1.66epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 205/3000 [02:04<28:04,  1.66epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 206/3000 [02:04<28:11,  1.65epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 206/3000 [02:04<28:11,  1.65epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 207/3000 [02:04<28:11,  1.65epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 207/3000 [02:05<28:11,  1.65epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 208/3000 [02:05<28:03,  1.66epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 208/3000 [02:05<28:03,  1.66epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 209/3000 [02:05<27:41,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 209/3000 [02:06<27:41,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 210/3000 [02:06<27:51,  1.67epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 210/3000 [02:07<27:51,  1.67epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 211/3000 [02:07<27:50,  1.67epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 211/3000 [02:07<27:50,  1.67epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 212/3000 [02:07<28:00,  1.66epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 212/3000 [02:08<28:00,  1.66epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 213/3000 [02:08<27:56,  1.66epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 213/3000 [02:08<27:56,  1.66epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 214/3000 [02:08<27:33,  1.69epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 214/3000 [02:09<27:33,  1.69epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 215/3000 [02:09<27:39,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 215/3000 [02:10<27:39,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 216/3000 [02:10<27:37,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 216/3000 [02:10<27:37,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 217/3000 [02:10<27:31,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 217/3000 [02:11<27:31,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 218/3000 [02:11<27:25,  1.69epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 218/3000 [02:11<27:25,  1.69epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 219/3000 [02:11<27:39,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 219/3000 [02:12<27:39,  1.68epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 220/3000 [02:12<27:13,  1.70epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 220/3000 [02:13<27:13,  1.70epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 221/3000 [02:13<26:59,  1.72epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 221/3000 [02:13<26:59,  1.72epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 222/3000 [02:13<27:02,  1.71epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 222/3000 [02:14<27:02,  1.71epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 223/3000 [02:14<27:05,  1.71epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 223/3000 [02:14<27:05,  1.71epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 224/3000 [02:14<27:19,  1.69epoch/s, Training loss (per batch)=0.01]Training:   7%|▋         | 224/3000 [02:15<27:19,  1.69epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 225/3000 [02:15<27:27,  1.68epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 225/3000 [02:16<27:27,  1.68epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 226/3000 [02:16<27:17,  1.69epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 226/3000 [02:16<27:17,  1.69epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 227/3000 [02:16<27:29,  1.68epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 227/3000 [02:17<27:29,  1.68epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 228/3000 [02:17<27:27,  1.68epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 228/3000 [02:17<27:27,  1.68epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 229/3000 [02:17<27:18,  1.69epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 229/3000 [02:18<27:18,  1.69epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 230/3000 [02:18<28:11,  1.64epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 230/3000 [02:19<28:11,  1.64epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 231/3000 [02:19<28:06,  1.64epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 231/3000 [02:19<28:06,  1.64epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 232/3000 [02:19<27:44,  1.66epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 232/3000 [02:20<27:44,  1.66epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 233/3000 [02:20<27:26,  1.68epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 233/3000 [02:20<27:26,  1.68epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 234/3000 [02:20<27:43,  1.66epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 234/3000 [02:21<27:43,  1.66epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 235/3000 [02:21<27:37,  1.67epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 235/3000 [02:22<27:37,  1.67epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 236/3000 [02:22<27:33,  1.67epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 236/3000 [02:22<27:33,  1.67epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 237/3000 [02:22<27:23,  1.68epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 237/3000 [02:23<27:23,  1.68epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 238/3000 [02:23<27:17,  1.69epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 238/3000 [02:23<27:17,  1.69epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 239/3000 [02:23<28:53,  1.59epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 239/3000 [02:24<28:53,  1.59epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 240/3000 [02:24<28:37,  1.61epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 240/3000 [02:25<28:37,  1.61epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 241/3000 [02:25<28:25,  1.62epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 241/3000 [02:25<28:25,  1.62epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 242/3000 [02:25<28:00,  1.64epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 242/3000 [02:26<28:00,  1.64epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 243/3000 [02:26<27:58,  1.64epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 243/3000 [02:26<27:58,  1.64epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 244/3000 [02:26<27:52,  1.65epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 244/3000 [02:27<27:52,  1.65epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 245/3000 [02:27<27:41,  1.66epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 245/3000 [02:28<27:41,  1.66epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 246/3000 [02:28<27:41,  1.66epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 246/3000 [02:28<27:41,  1.66epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 247/3000 [02:28<27:35,  1.66epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 247/3000 [02:29<27:35,  1.66epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 248/3000 [02:29<27:45,  1.65epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 248/3000 [02:29<27:45,  1.65epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 249/3000 [02:29<27:51,  1.65epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 249/3000 [02:30<27:51,  1.65epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 250/3000 [02:30<27:58,  1.64epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 250/3000 [02:31<27:58,  1.64epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 251/3000 [02:31<27:43,  1.65epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 251/3000 [02:31<27:43,  1.65epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 252/3000 [02:31<27:46,  1.65epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 252/3000 [02:32<27:46,  1.65epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 253/3000 [02:32<27:46,  1.65epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 253/3000 [02:33<27:46,  1.65epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 254/3000 [02:33<27:46,  1.65epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 254/3000 [02:33<27:46,  1.65epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 255/3000 [02:33<27:36,  1.66epoch/s, Training loss (per batch)=0.01]Training:   8%|▊         | 255/3000 [02:34<27:36,  1.66epoch/s, Training loss (per batch)=0.01]Training:   9%|▊         | 256/3000 [02:34<27:17,  1.68epoch/s, Training loss (per batch)=0.01]Training:   9%|▊         | 256/3000 [02:34<27:17,  1.68epoch/s, Training loss (per batch)=0.01]Training:   9%|▊         | 257/3000 [02:34<27:27,  1.67epoch/s, Training loss (per batch)=0.01]Training:   9%|▊         | 257/3000 [02:35<27:27,  1.67epoch/s, Training loss (per batch)=0.01]Training:   9%|▊         | 258/3000 [02:35<27:33,  1.66epoch/s, Training loss (per batch)=0.01]Training:   9%|▊         | 258/3000 [02:36<27:33,  1.66epoch/s, Training loss (per batch)=0.01]Training:   9%|▊         | 259/3000 [02:36<27:33,  1.66epoch/s, Training loss (per batch)=0.01]Training:   9%|▊         | 259/3000 [02:36<27:33,  1.66epoch/s, Training loss (per batch)=0.01]Training:   9%|▊         | 260/3000 [02:36<27:18,  1.67epoch/s, Training loss (per batch)=0.01]Training:   9%|▊         | 260/3000 [02:37<27:18,  1.67epoch/s, Training loss (per batch)=0.01]Training:   9%|▊         | 261/3000 [02:37<27:19,  1.67epoch/s, Training loss (per batch)=0.01]Training:   9%|▊         | 261/3000 [02:37<27:19,  1.67epoch/s, Training loss (per batch)=0.01]Training:   9%|▊         | 262/3000 [02:37<27:06,  1.68epoch/s, Training loss (per batch)=0.01]Training:   9%|▊         | 262/3000 [02:38<27:06,  1.68epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 263/3000 [02:38<26:55,  1.69epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 263/3000 [02:38<26:55,  1.69epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 264/3000 [02:38<27:08,  1.68epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 264/3000 [02:39<27:08,  1.68epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 265/3000 [02:39<27:21,  1.67epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 265/3000 [02:40<27:21,  1.67epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 266/3000 [02:40<27:36,  1.65epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 266/3000 [02:40<27:36,  1.65epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 267/3000 [02:40<27:38,  1.65epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 267/3000 [02:41<27:38,  1.65epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 268/3000 [02:41<27:38,  1.65epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 268/3000 [02:42<27:38,  1.65epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 269/3000 [02:42<27:36,  1.65epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 269/3000 [02:42<27:36,  1.65epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 270/3000 [02:42<27:34,  1.65epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 270/3000 [02:43<27:34,  1.65epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 271/3000 [02:43<27:36,  1.65epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 271/3000 [02:43<27:36,  1.65epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 272/3000 [02:43<27:10,  1.67epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 272/3000 [02:44<27:10,  1.67epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 273/3000 [02:44<27:05,  1.68epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 273/3000 [02:44<27:05,  1.68epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 274/3000 [02:44<27:03,  1.68epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 274/3000 [02:45<27:03,  1.68epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 275/3000 [02:45<27:41,  1.64epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 275/3000 [02:46<27:41,  1.64epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 276/3000 [02:46<27:53,  1.63epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 276/3000 [02:46<27:53,  1.63epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 277/3000 [02:46<27:17,  1.66epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 277/3000 [02:47<27:17,  1.66epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 278/3000 [02:47<27:17,  1.66epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 278/3000 [02:48<27:17,  1.66epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 279/3000 [02:48<27:17,  1.66epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 279/3000 [02:48<27:17,  1.66epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 280/3000 [02:48<27:38,  1.64epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 280/3000 [02:49<27:38,  1.64epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 281/3000 [02:49<27:09,  1.67epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 281/3000 [02:49<27:09,  1.67epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 282/3000 [02:49<26:47,  1.69epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 282/3000 [02:50<26:47,  1.69epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 283/3000 [02:50<26:41,  1.70epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 283/3000 [02:50<26:41,  1.70epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 284/3000 [02:50<26:41,  1.70epoch/s, Training loss (per batch)=0.01]Training:   9%|▉         | 284/3000 [02:51<26:41,  1.70epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 285/3000 [02:51<26:42,  1.69epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 285/3000 [02:52<26:42,  1.69epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 286/3000 [02:52<26:54,  1.68epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 286/3000 [02:52<26:54,  1.68epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 287/3000 [02:52<26:47,  1.69epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 287/3000 [02:53<26:47,  1.69epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 288/3000 [02:53<27:03,  1.67epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 288/3000 [02:54<27:03,  1.67epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 289/3000 [02:54<27:11,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 289/3000 [02:54<27:11,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 290/3000 [02:54<27:07,  1.67epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 290/3000 [02:55<27:07,  1.67epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 291/3000 [02:55<27:09,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 291/3000 [02:55<27:09,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 292/3000 [02:55<27:11,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 292/3000 [02:56<27:11,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 293/3000 [02:56<27:07,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 293/3000 [02:57<27:07,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 294/3000 [02:57<27:01,  1.67epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 294/3000 [02:57<27:01,  1.67epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 295/3000 [02:57<27:09,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 295/3000 [02:58<27:09,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 296/3000 [02:58<26:46,  1.68epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 296/3000 [02:58<26:46,  1.68epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 297/3000 [02:58<26:42,  1.69epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 297/3000 [02:59<26:42,  1.69epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 298/3000 [02:59<26:43,  1.69epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 298/3000 [02:59<26:43,  1.69epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 299/3000 [02:59<26:47,  1.68epoch/s, Training loss (per batch)=0.01]Training:  10%|▉         | 299/3000 [03:00<26:47,  1.68epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 300/3000 [03:00<27:06,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 300/3000 [03:01<27:06,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 301/3000 [03:01<27:06,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 301/3000 [03:01<27:06,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 302/3000 [03:01<27:12,  1.65epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 302/3000 [03:02<27:12,  1.65epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 303/3000 [03:02<27:10,  1.65epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 303/3000 [03:03<27:10,  1.65epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 304/3000 [03:03<27:06,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 304/3000 [03:03<27:06,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 305/3000 [03:03<27:00,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 305/3000 [03:04<27:00,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 306/3000 [03:04<26:47,  1.68epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 306/3000 [03:04<26:47,  1.68epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 307/3000 [03:04<26:45,  1.68epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 307/3000 [03:05<26:45,  1.68epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 308/3000 [03:05<26:59,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 308/3000 [03:05<26:59,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 309/3000 [03:05<26:56,  1.67epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 309/3000 [03:06<26:56,  1.67epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 310/3000 [03:06<27:07,  1.65epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 310/3000 [03:07<27:07,  1.65epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 311/3000 [03:07<27:02,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 311/3000 [03:07<27:02,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 312/3000 [03:07<26:54,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 312/3000 [03:08<26:54,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 313/3000 [03:08<27:00,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 313/3000 [03:09<27:00,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 314/3000 [03:09<26:55,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 314/3000 [03:09<26:55,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 315/3000 [03:09<26:54,  1.66epoch/s, Training loss (per batch)=0.01]Training:  10%|█         | 315/3000 [03:10<26:54,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 316/3000 [03:10<26:48,  1.67epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 316/3000 [03:10<26:48,  1.67epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 317/3000 [03:10<27:00,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 317/3000 [03:11<27:00,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 318/3000 [03:11<27:01,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 318/3000 [03:12<27:01,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 319/3000 [03:12<27:00,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 319/3000 [03:12<27:00,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 320/3000 [03:12<27:05,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 320/3000 [03:13<27:05,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 321/3000 [03:13<27:06,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 321/3000 [03:13<27:06,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 322/3000 [03:13<27:03,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 322/3000 [03:14<27:03,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 323/3000 [03:14<26:58,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 323/3000 [03:15<26:58,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 324/3000 [03:15<26:47,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 324/3000 [03:15<26:47,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 325/3000 [03:15<26:44,  1.67epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 325/3000 [03:16<26:44,  1.67epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 326/3000 [03:16<27:09,  1.64epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 326/3000 [03:16<27:09,  1.64epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 327/3000 [03:16<26:49,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 327/3000 [03:17<26:49,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 328/3000 [03:17<26:51,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 328/3000 [03:18<26:51,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 329/3000 [03:18<27:09,  1.64epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 329/3000 [03:18<27:09,  1.64epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 330/3000 [03:18<26:48,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 330/3000 [03:19<26:48,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 331/3000 [03:19<26:42,  1.67epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 331/3000 [03:19<26:42,  1.67epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 332/3000 [03:19<26:39,  1.67epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 332/3000 [03:20<26:39,  1.67epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 333/3000 [03:20<26:32,  1.67epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 333/3000 [03:21<26:32,  1.67epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 334/3000 [03:21<26:34,  1.67epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 334/3000 [03:21<26:34,  1.67epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 335/3000 [03:21<26:41,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 335/3000 [03:22<26:41,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 336/3000 [03:22<26:41,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 336/3000 [03:22<26:41,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 337/3000 [03:22<26:58,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█         | 337/3000 [03:23<26:58,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█▏        | 338/3000 [03:23<26:46,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█▏        | 338/3000 [03:24<26:46,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█▏        | 339/3000 [03:24<26:44,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█▏        | 339/3000 [03:24<26:44,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█▏        | 340/3000 [03:24<26:42,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█▏        | 340/3000 [03:25<26:42,  1.66epoch/s, Training loss (per batch)=0.01]Training:  11%|█▏        | 341/3000 [03:25<26:53,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█▏        | 341/3000 [03:25<26:53,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█▏        | 342/3000 [03:25<26:50,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█▏        | 342/3000 [03:26<26:50,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█▏        | 343/3000 [03:26<26:54,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█▏        | 343/3000 [03:27<26:54,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█▏        | 344/3000 [03:27<26:48,  1.65epoch/s, Training loss (per batch)=0.01]Training:  11%|█▏        | 344/3000 [03:27<26:48,  1.65epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 345/3000 [03:27<26:41,  1.66epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 345/3000 [03:28<26:41,  1.66epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 346/3000 [03:28<26:25,  1.67epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 346/3000 [03:28<26:25,  1.67epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 347/3000 [03:28<26:13,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 347/3000 [03:29<26:13,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 348/3000 [03:29<26:23,  1.67epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 348/3000 [03:30<26:23,  1.67epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 349/3000 [03:30<26:19,  1.68epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 349/3000 [03:30<26:19,  1.68epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 350/3000 [03:30<26:35,  1.66epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 350/3000 [03:31<26:35,  1.66epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 351/3000 [03:31<26:43,  1.65epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 351/3000 [03:31<26:43,  1.65epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 352/3000 [03:31<26:11,  1.68epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 352/3000 [03:32<26:11,  1.68epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 353/3000 [03:32<26:13,  1.68epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 353/3000 [03:33<26:13,  1.68epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 354/3000 [03:33<26:06,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 354/3000 [03:33<26:06,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 355/3000 [03:33<25:57,  1.70epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 355/3000 [03:34<25:57,  1.70epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 356/3000 [03:34<25:48,  1.71epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 356/3000 [03:34<25:48,  1.71epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 357/3000 [03:34<25:59,  1.70epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 357/3000 [03:35<25:59,  1.70epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 358/3000 [03:35<26:22,  1.67epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 358/3000 [03:36<26:22,  1.67epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 359/3000 [03:36<25:58,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 359/3000 [03:36<25:58,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 360/3000 [03:36<25:55,  1.70epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 360/3000 [03:37<25:55,  1.70epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 361/3000 [03:37<25:59,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 361/3000 [03:37<25:59,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 362/3000 [03:37<26:13,  1.68epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 362/3000 [03:38<26:13,  1.68epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 363/3000 [03:38<26:12,  1.68epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 363/3000 [03:38<26:12,  1.68epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 364/3000 [03:38<26:04,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 364/3000 [03:39<26:04,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 365/3000 [03:39<26:00,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 365/3000 [03:40<26:00,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 366/3000 [03:40<25:49,  1.70epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 366/3000 [03:40<25:49,  1.70epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 367/3000 [03:40<25:53,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 367/3000 [03:41<25:53,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 368/3000 [03:41<25:41,  1.71epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 368/3000 [03:41<25:41,  1.71epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 369/3000 [03:41<25:35,  1.71epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 369/3000 [03:42<25:35,  1.71epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 370/3000 [03:42<26:00,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 370/3000 [03:43<26:00,  1.69epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 371/3000 [03:43<26:14,  1.67epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 371/3000 [03:43<26:14,  1.67epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 372/3000 [03:43<26:08,  1.68epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 372/3000 [03:44<26:08,  1.68epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 373/3000 [03:44<26:11,  1.67epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 373/3000 [03:44<26:11,  1.67epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 374/3000 [03:44<26:07,  1.67epoch/s, Training loss (per batch)=0.01]Training:  12%|█▏        | 374/3000 [03:45<26:07,  1.67epoch/s, Training loss (per batch)=0.01]Training:  12%|█▎        | 375/3000 [03:45<26:18,  1.66epoch/s, Training loss (per batch)=0.01]Training:  12%|█▎        | 375/3000 [03:46<26:18,  1.66epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 376/3000 [03:46<26:37,  1.64epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 376/3000 [03:46<26:37,  1.64epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 377/3000 [03:46<26:11,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 377/3000 [03:47<26:11,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 378/3000 [03:47<26:21,  1.66epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 378/3000 [03:47<26:21,  1.66epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 379/3000 [03:47<26:13,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 379/3000 [03:48<26:13,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 380/3000 [03:48<26:15,  1.66epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 380/3000 [03:49<26:15,  1.66epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 381/3000 [03:49<26:05,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 381/3000 [03:49<26:05,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 382/3000 [03:49<26:04,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 382/3000 [03:50<26:04,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 383/3000 [03:50<26:06,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 383/3000 [03:50<26:06,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 384/3000 [03:50<25:56,  1.68epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 384/3000 [03:51<25:56,  1.68epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 385/3000 [03:51<26:00,  1.68epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 385/3000 [03:52<26:00,  1.68epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 386/3000 [03:52<25:50,  1.69epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 386/3000 [03:52<25:50,  1.69epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 387/3000 [03:52<25:54,  1.68epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 387/3000 [03:53<25:54,  1.68epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 388/3000 [03:53<25:54,  1.68epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 388/3000 [03:53<25:54,  1.68epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 389/3000 [03:53<26:02,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 389/3000 [03:54<26:02,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 390/3000 [03:54<26:05,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 390/3000 [03:55<26:05,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 391/3000 [03:55<26:05,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 391/3000 [03:55<26:05,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 392/3000 [03:55<26:00,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 392/3000 [03:56<26:00,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 393/3000 [03:56<25:36,  1.70epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 393/3000 [03:56<25:36,  1.70epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 394/3000 [03:56<26:01,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 394/3000 [03:57<26:01,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 395/3000 [03:57<26:06,  1.66epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 395/3000 [03:58<26:06,  1.66epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 396/3000 [03:58<26:00,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 396/3000 [03:58<26:00,  1.67epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 397/3000 [03:58<25:50,  1.68epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 397/3000 [03:59<25:50,  1.68epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 398/3000 [03:59<25:51,  1.68epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 398/3000 [03:59<25:51,  1.68epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 399/3000 [03:59<25:32,  1.70epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 399/3000 [04:00<25:32,  1.70epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 400/3000 [04:00<26:35,  1.63epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 400/3000 [04:01<26:35,  1.63epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 401/3000 [04:01<26:21,  1.64epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 401/3000 [04:01<26:21,  1.64epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 402/3000 [04:01<26:21,  1.64epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 402/3000 [04:02<26:21,  1.64epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 403/3000 [04:02<26:18,  1.65epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 403/3000 [04:02<26:18,  1.65epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 404/3000 [04:02<26:21,  1.64epoch/s, Training loss (per batch)=0.01]Training:  13%|█▎        | 404/3000 [04:03<26:21,  1.64epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 405/3000 [04:03<26:12,  1.65epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 405/3000 [04:04<26:12,  1.65epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 406/3000 [04:04<26:08,  1.65epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 406/3000 [04:04<26:08,  1.65epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 407/3000 [04:04<26:03,  1.66epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 407/3000 [04:05<26:03,  1.66epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 408/3000 [04:05<25:53,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 408/3000 [04:05<25:53,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 409/3000 [04:05<26:10,  1.65epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 409/3000 [04:06<26:10,  1.65epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 410/3000 [04:06<26:01,  1.66epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 410/3000 [04:07<26:01,  1.66epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 411/3000 [04:07<26:01,  1.66epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 411/3000 [04:07<26:01,  1.66epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 412/3000 [04:07<25:54,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▎        | 412/3000 [04:08<25:54,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 413/3000 [04:08<25:44,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 413/3000 [04:08<25:44,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 414/3000 [04:08<25:55,  1.66epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 414/3000 [04:09<25:55,  1.66epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 415/3000 [04:09<25:44,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 415/3000 [04:10<25:44,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 416/3000 [04:10<25:43,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 416/3000 [04:10<25:43,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 417/3000 [04:10<25:24,  1.69epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 417/3000 [04:11<25:24,  1.69epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 418/3000 [04:11<25:43,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 418/3000 [04:11<25:43,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 419/3000 [04:11<25:44,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 419/3000 [04:12<25:44,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 420/3000 [04:12<25:44,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 420/3000 [04:13<25:44,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 421/3000 [04:13<26:00,  1.65epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 421/3000 [04:13<26:00,  1.65epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 422/3000 [04:13<25:58,  1.65epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 422/3000 [04:14<25:58,  1.65epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 423/3000 [04:14<25:49,  1.66epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 423/3000 [04:14<25:49,  1.66epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 424/3000 [04:14<25:50,  1.66epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 424/3000 [04:15<25:50,  1.66epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 425/3000 [04:15<25:42,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 425/3000 [04:16<25:42,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 426/3000 [04:16<25:33,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 426/3000 [04:16<25:33,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 427/3000 [04:16<25:31,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 427/3000 [04:17<25:31,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 428/3000 [04:17<25:32,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 428/3000 [04:17<25:32,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 429/3000 [04:17<25:30,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 429/3000 [04:18<25:30,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 430/3000 [04:18<25:33,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 430/3000 [04:19<25:33,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 431/3000 [04:19<25:31,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 431/3000 [04:19<25:31,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 432/3000 [04:19<25:20,  1.69epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 432/3000 [04:20<25:20,  1.69epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 433/3000 [04:20<25:31,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 433/3000 [04:20<25:31,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 434/3000 [04:20<25:31,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 434/3000 [04:21<25:31,  1.68epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 435/3000 [04:21<25:35,  1.67epoch/s, Training loss (per batch)=0.01]Training:  14%|█▍        | 435/3000 [04:22<25:35,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 436/3000 [04:22<25:33,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 436/3000 [04:22<25:33,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 437/3000 [04:22<25:18,  1.69epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 437/3000 [04:23<25:18,  1.69epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 438/3000 [04:23<25:25,  1.68epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 438/3000 [04:23<25:25,  1.68epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 439/3000 [04:23<25:32,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 439/3000 [04:24<25:32,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 440/3000 [04:24<25:45,  1.66epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 440/3000 [04:25<25:45,  1.66epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 441/3000 [04:25<25:45,  1.66epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 441/3000 [04:25<25:45,  1.66epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 442/3000 [04:25<25:44,  1.66epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 442/3000 [04:26<25:44,  1.66epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 443/3000 [04:26<25:35,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 443/3000 [04:26<25:35,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 444/3000 [04:26<25:24,  1.68epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 444/3000 [04:27<25:24,  1.68epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 445/3000 [04:27<25:31,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 445/3000 [04:28<25:31,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 446/3000 [04:28<25:38,  1.66epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 446/3000 [04:28<25:38,  1.66epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 447/3000 [04:28<25:33,  1.66epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 447/3000 [04:29<25:33,  1.66epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 448/3000 [04:29<25:30,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 448/3000 [04:29<25:30,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 449/3000 [04:29<25:26,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▍        | 449/3000 [04:30<25:26,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 450/3000 [04:30<25:52,  1.64epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 450/3000 [04:31<25:52,  1.64epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 451/3000 [04:31<25:59,  1.63epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 451/3000 [04:31<25:59,  1.63epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 452/3000 [04:31<25:49,  1.64epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 452/3000 [04:32<25:49,  1.64epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 453/3000 [04:32<25:50,  1.64epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 453/3000 [04:32<25:50,  1.64epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 454/3000 [04:32<25:36,  1.66epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 454/3000 [04:33<25:36,  1.66epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 455/3000 [04:33<25:06,  1.69epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 455/3000 [04:34<25:06,  1.69epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 456/3000 [04:34<25:13,  1.68epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 456/3000 [04:34<25:13,  1.68epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 457/3000 [04:34<25:16,  1.68epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 457/3000 [04:35<25:16,  1.68epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 458/3000 [04:35<25:00,  1.69epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 458/3000 [04:35<25:00,  1.69epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 459/3000 [04:35<25:03,  1.69epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 459/3000 [04:36<25:03,  1.69epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 460/3000 [04:36<25:04,  1.69epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 460/3000 [04:37<25:04,  1.69epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 461/3000 [04:37<25:11,  1.68epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 461/3000 [04:37<25:11,  1.68epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 462/3000 [04:37<25:15,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 462/3000 [04:38<25:15,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 463/3000 [04:38<25:16,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 463/3000 [04:38<25:16,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 464/3000 [04:38<25:14,  1.67epoch/s, Training loss (per batch)=0.01]Training:  15%|█▌        | 464/3000 [04:39<25:14,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 465/3000 [04:39<25:21,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 465/3000 [04:40<25:21,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 466/3000 [04:40<25:18,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 466/3000 [04:40<25:18,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 467/3000 [04:40<25:23,  1.66epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 467/3000 [04:41<25:23,  1.66epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 468/3000 [04:41<25:22,  1.66epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 468/3000 [04:41<25:22,  1.66epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 469/3000 [04:41<25:19,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 469/3000 [04:42<25:19,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 470/3000 [04:42<25:19,  1.66epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 470/3000 [04:43<25:19,  1.66epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 471/3000 [04:43<25:24,  1.66epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 471/3000 [04:43<25:24,  1.66epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 472/3000 [04:43<24:58,  1.69epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 472/3000 [04:44<24:58,  1.69epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 473/3000 [04:44<25:10,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 473/3000 [04:44<25:10,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 474/3000 [04:44<25:08,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 474/3000 [04:45<25:08,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 475/3000 [04:45<25:28,  1.65epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 475/3000 [04:46<25:28,  1.65epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 476/3000 [04:46<25:47,  1.63epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 476/3000 [04:46<25:47,  1.63epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 477/3000 [04:46<25:43,  1.63epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 477/3000 [04:47<25:43,  1.63epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 478/3000 [04:47<25:32,  1.65epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 478/3000 [04:47<25:32,  1.65epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 479/3000 [04:47<25:31,  1.65epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 479/3000 [04:48<25:31,  1.65epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 480/3000 [04:48<25:11,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 480/3000 [04:49<25:11,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 481/3000 [04:49<25:14,  1.66epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 481/3000 [04:49<25:14,  1.66epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 482/3000 [04:49<25:07,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 482/3000 [04:50<25:07,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 483/3000 [04:50<25:09,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 483/3000 [04:50<25:09,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 484/3000 [04:50<24:55,  1.68epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 484/3000 [04:51<24:55,  1.68epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 485/3000 [04:51<24:59,  1.68epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 485/3000 [04:52<24:59,  1.68epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 486/3000 [04:52<25:01,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 486/3000 [04:52<25:01,  1.67epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 487/3000 [04:52<24:47,  1.69epoch/s, Training loss (per batch)=0.01]Training:  16%|█▌        | 487/3000 [04:53<24:47,  1.69epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 488/3000 [04:53<24:39,  1.70epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 488/3000 [04:53<24:39,  1.70epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 489/3000 [04:53<24:30,  1.71epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 489/3000 [04:54<24:30,  1.71epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 490/3000 [04:54<24:25,  1.71epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 490/3000 [04:55<24:25,  1.71epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 491/3000 [04:55<24:32,  1.70epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 491/3000 [04:55<24:32,  1.70epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 492/3000 [04:55<24:46,  1.69epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 492/3000 [04:56<24:46,  1.69epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 493/3000 [04:56<24:47,  1.69epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 493/3000 [04:56<24:47,  1.69epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 494/3000 [04:56<24:45,  1.69epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 494/3000 [04:57<24:45,  1.69epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 495/3000 [04:57<24:31,  1.70epoch/s, Training loss (per batch)=0.01]Training:  16%|█▋        | 495/3000 [04:57<24:31,  1.70epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 496/3000 [04:57<24:42,  1.69epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 496/3000 [04:58<24:42,  1.69epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 497/3000 [04:58<24:24,  1.71epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 497/3000 [04:59<24:24,  1.71epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 498/3000 [04:59<24:15,  1.72epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 498/3000 [04:59<24:15,  1.72epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 499/3000 [04:59<24:18,  1.71epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 499/3000 [05:00<24:18,  1.71epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 500/3000 [05:00<24:53,  1.67epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 500/3000 [05:00<24:53,  1.67epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 501/3000 [05:00<24:56,  1.67epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 501/3000 [05:01<24:56,  1.67epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 502/3000 [05:01<25:02,  1.66epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 502/3000 [05:02<25:02,  1.66epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 503/3000 [05:02<25:01,  1.66epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 503/3000 [05:02<25:01,  1.66epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 504/3000 [05:02<24:52,  1.67epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 504/3000 [05:03<24:52,  1.67epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 505/3000 [05:03<24:29,  1.70epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 505/3000 [05:03<24:29,  1.70epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 506/3000 [05:03<24:37,  1.69epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 506/3000 [05:04<24:37,  1.69epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 507/3000 [05:04<24:29,  1.70epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 507/3000 [05:05<24:29,  1.70epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 508/3000 [05:05<24:48,  1.67epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 508/3000 [05:05<24:48,  1.67epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 509/3000 [05:05<24:33,  1.69epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 509/3000 [05:06<24:33,  1.69epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 510/3000 [05:06<24:23,  1.70epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 510/3000 [05:06<24:23,  1.70epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 511/3000 [05:06<24:30,  1.69epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 511/3000 [05:07<24:30,  1.69epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 512/3000 [05:07<24:34,  1.69epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 512/3000 [05:08<24:34,  1.69epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 513/3000 [05:08<24:42,  1.68epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 513/3000 [05:08<24:42,  1.68epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 514/3000 [05:08<24:41,  1.68epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 514/3000 [05:09<24:41,  1.68epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 515/3000 [05:09<24:51,  1.67epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 515/3000 [05:09<24:51,  1.67epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 516/3000 [05:09<24:55,  1.66epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 516/3000 [05:10<24:55,  1.66epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 517/3000 [05:10<24:57,  1.66epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 517/3000 [05:11<24:57,  1.66epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 518/3000 [05:11<24:52,  1.66epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 518/3000 [05:11<24:52,  1.66epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 519/3000 [05:11<24:58,  1.66epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 519/3000 [05:12<24:58,  1.66epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 520/3000 [05:12<24:47,  1.67epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 520/3000 [05:12<24:47,  1.67epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 521/3000 [05:12<25:07,  1.64epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 521/3000 [05:13<25:07,  1.64epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 522/3000 [05:13<25:17,  1.63epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 522/3000 [05:14<25:17,  1.63epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 523/3000 [05:14<25:15,  1.63epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 523/3000 [05:14<25:15,  1.63epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 524/3000 [05:14<25:09,  1.64epoch/s, Training loss (per batch)=0.01]Training:  17%|█▋        | 524/3000 [05:15<25:09,  1.64epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 525/3000 [05:15<24:57,  1.65epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 525/3000 [05:15<24:57,  1.65epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 526/3000 [05:15<24:49,  1.66epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 526/3000 [05:16<24:49,  1.66epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 527/3000 [05:16<24:43,  1.67epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 527/3000 [05:17<24:43,  1.67epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 528/3000 [05:17<24:37,  1.67epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 528/3000 [05:17<24:37,  1.67epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 529/3000 [05:17<24:29,  1.68epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 529/3000 [05:18<24:29,  1.68epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 530/3000 [05:18<24:43,  1.66epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 530/3000 [05:18<24:43,  1.66epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 531/3000 [05:18<24:29,  1.68epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 531/3000 [05:19<24:29,  1.68epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 532/3000 [05:19<24:46,  1.66epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 532/3000 [05:20<24:46,  1.66epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 533/3000 [05:20<24:36,  1.67epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 533/3000 [05:20<24:36,  1.67epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 534/3000 [05:20<24:37,  1.67epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 534/3000 [05:21<24:37,  1.67epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 535/3000 [05:21<24:59,  1.64epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 535/3000 [05:21<24:59,  1.64epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 536/3000 [05:21<24:51,  1.65epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 536/3000 [05:22<24:51,  1.65epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 537/3000 [05:22<24:44,  1.66epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 537/3000 [05:23<24:44,  1.66epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 538/3000 [05:23<24:49,  1.65epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 538/3000 [05:23<24:49,  1.65epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 539/3000 [05:23<24:42,  1.66epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 539/3000 [05:24<24:42,  1.66epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 540/3000 [05:24<24:37,  1.67epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 540/3000 [05:24<24:37,  1.67epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 541/3000 [05:24<24:39,  1.66epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 541/3000 [05:25<24:39,  1.66epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 542/3000 [05:25<24:38,  1.66epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 542/3000 [05:26<24:38,  1.66epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 543/3000 [05:26<24:27,  1.67epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 543/3000 [05:26<24:27,  1.67epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 544/3000 [05:26<24:28,  1.67epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 544/3000 [05:27<24:28,  1.67epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 545/3000 [05:27<24:24,  1.68epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 545/3000 [05:27<24:24,  1.68epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 546/3000 [05:27<24:11,  1.69epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 546/3000 [05:28<24:11,  1.69epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 547/3000 [05:28<24:02,  1.70epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 547/3000 [05:29<24:02,  1.70epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 548/3000 [05:29<24:09,  1.69epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 548/3000 [05:29<24:09,  1.69epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 549/3000 [05:29<24:45,  1.65epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 549/3000 [05:30<24:45,  1.65epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 550/3000 [05:30<24:54,  1.64epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 550/3000 [05:30<24:54,  1.64epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 551/3000 [05:30<24:57,  1.64epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 551/3000 [05:31<24:57,  1.64epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 552/3000 [05:31<24:48,  1.64epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 552/3000 [05:32<24:48,  1.64epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 553/3000 [05:32<24:45,  1.65epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 553/3000 [05:32<24:45,  1.65epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 554/3000 [05:32<24:45,  1.65epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 554/3000 [05:33<24:45,  1.65epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 555/3000 [05:33<24:39,  1.65epoch/s, Training loss (per batch)=0.01]Training:  18%|█▊        | 555/3000 [05:33<24:39,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▊        | 556/3000 [05:33<24:38,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▊        | 556/3000 [05:34<24:38,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▊        | 557/3000 [05:34<24:36,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▊        | 557/3000 [05:35<24:36,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▊        | 558/3000 [05:35<24:46,  1.64epoch/s, Training loss (per batch)=0.01]Training:  19%|█▊        | 558/3000 [05:35<24:46,  1.64epoch/s, Training loss (per batch)=0.01]Training:  19%|█▊        | 559/3000 [05:35<24:29,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▊        | 559/3000 [05:36<24:29,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▊        | 560/3000 [05:36<24:28,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▊        | 560/3000 [05:37<24:28,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▊        | 561/3000 [05:37<24:37,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▊        | 561/3000 [05:37<24:37,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▊        | 562/3000 [05:37<24:27,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▊        | 562/3000 [05:38<24:27,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 563/3000 [05:38<24:24,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 563/3000 [05:38<24:24,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 564/3000 [05:38<24:24,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 564/3000 [05:39<24:24,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 565/3000 [05:39<24:33,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 565/3000 [05:40<24:33,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 566/3000 [05:40<24:53,  1.63epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 566/3000 [05:40<24:53,  1.63epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 567/3000 [05:40<24:45,  1.64epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 567/3000 [05:41<24:45,  1.64epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 568/3000 [05:41<24:13,  1.67epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 568/3000 [05:41<24:13,  1.67epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 569/3000 [05:41<24:18,  1.67epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 569/3000 [05:42<24:18,  1.67epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 570/3000 [05:42<24:17,  1.67epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 570/3000 [05:43<24:17,  1.67epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 571/3000 [05:43<24:25,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 571/3000 [05:43<24:25,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 572/3000 [05:43<24:17,  1.67epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 572/3000 [05:44<24:17,  1.67epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 573/3000 [05:44<24:26,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 573/3000 [05:44<24:26,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 574/3000 [05:44<24:27,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 574/3000 [05:45<24:27,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 575/3000 [05:45<24:31,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 575/3000 [05:46<24:31,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 576/3000 [05:46<24:25,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 576/3000 [05:46<24:25,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 577/3000 [05:46<24:25,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 577/3000 [05:47<24:25,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 578/3000 [05:47<24:10,  1.67epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 578/3000 [05:47<24:10,  1.67epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 579/3000 [05:47<23:54,  1.69epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 579/3000 [05:48<23:54,  1.69epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 580/3000 [05:48<24:16,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 580/3000 [05:49<24:16,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 581/3000 [05:49<24:20,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 581/3000 [05:49<24:20,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 582/3000 [05:49<24:26,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 582/3000 [05:50<24:26,  1.65epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 583/3000 [05:50<24:17,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 583/3000 [05:50<24:17,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 584/3000 [05:50<24:15,  1.66epoch/s, Training loss (per batch)=0.01]Training:  19%|█▉        | 584/3000 [05:51<24:15,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 585/3000 [05:51<23:57,  1.68epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 585/3000 [05:52<23:57,  1.68epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 586/3000 [05:52<24:12,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 586/3000 [05:52<24:12,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 587/3000 [05:52<24:26,  1.65epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 587/3000 [05:53<24:26,  1.65epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 588/3000 [05:53<24:25,  1.65epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 588/3000 [05:53<24:25,  1.65epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 589/3000 [05:53<24:11,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 589/3000 [05:54<24:11,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 590/3000 [05:54<24:02,  1.67epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 590/3000 [05:55<24:02,  1.67epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 591/3000 [05:55<24:10,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 591/3000 [05:55<24:10,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 592/3000 [05:55<24:09,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 592/3000 [05:56<24:09,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 593/3000 [05:56<24:00,  1.67epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 593/3000 [05:56<24:00,  1.67epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 594/3000 [05:56<24:03,  1.67epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 594/3000 [05:57<24:03,  1.67epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 595/3000 [05:57<23:54,  1.68epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 595/3000 [05:58<23:54,  1.68epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 596/3000 [05:58<24:07,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 596/3000 [05:58<24:07,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 597/3000 [05:58<24:13,  1.65epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 597/3000 [05:59<24:13,  1.65epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 598/3000 [05:59<23:57,  1.67epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 598/3000 [05:59<23:57,  1.67epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 599/3000 [05:59<23:59,  1.67epoch/s, Training loss (per batch)=0.01]Training:  20%|█▉        | 599/3000 [06:00<23:59,  1.67epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 600/3000 [06:00<24:53,  1.61epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 600/3000 [06:01<24:53,  1.61epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 601/3000 [06:01<24:24,  1.64epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 601/3000 [06:01<24:24,  1.64epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 602/3000 [06:01<24:27,  1.63epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 602/3000 [06:02<24:27,  1.63epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 603/3000 [06:02<24:14,  1.65epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 603/3000 [06:02<24:14,  1.65epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 604/3000 [06:02<24:14,  1.65epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 604/3000 [06:03<24:14,  1.65epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 605/3000 [06:03<24:19,  1.64epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 605/3000 [06:04<24:19,  1.64epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 606/3000 [06:04<24:14,  1.65epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 606/3000 [06:04<24:14,  1.65epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 607/3000 [06:04<24:04,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 607/3000 [06:05<24:04,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 608/3000 [06:05<23:54,  1.67epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 608/3000 [06:05<23:54,  1.67epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 609/3000 [06:05<23:59,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 609/3000 [06:06<23:59,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 610/3000 [06:06<24:03,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 610/3000 [06:07<24:03,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 611/3000 [06:07<23:56,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 611/3000 [06:07<23:56,  1.66epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 612/3000 [06:07<23:51,  1.67epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 612/3000 [06:08<23:51,  1.67epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 613/3000 [06:08<23:42,  1.68epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 613/3000 [06:08<23:42,  1.68epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 614/3000 [06:08<23:43,  1.68epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 614/3000 [06:09<23:43,  1.68epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 615/3000 [06:09<23:49,  1.67epoch/s, Training loss (per batch)=0.01]Training:  20%|██        | 615/3000 [06:10<23:49,  1.67epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 616/3000 [06:10<23:55,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 616/3000 [06:10<23:55,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 617/3000 [06:10<24:02,  1.65epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 617/3000 [06:11<24:02,  1.65epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 618/3000 [06:11<24:00,  1.65epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 618/3000 [06:11<24:00,  1.65epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 619/3000 [06:11<24:00,  1.65epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 619/3000 [06:12<24:00,  1.65epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 620/3000 [06:12<24:13,  1.64epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 620/3000 [06:13<24:13,  1.64epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 621/3000 [06:13<23:31,  1.68epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 621/3000 [06:13<23:31,  1.68epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 622/3000 [06:13<23:35,  1.68epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 622/3000 [06:14<23:35,  1.68epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 623/3000 [06:14<23:38,  1.68epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 623/3000 [06:14<23:38,  1.68epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 624/3000 [06:14<23:48,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 624/3000 [06:15<23:48,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 625/3000 [06:15<23:49,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 625/3000 [06:16<23:49,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 626/3000 [06:16<23:50,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 626/3000 [06:16<23:50,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 627/3000 [06:16<23:35,  1.68epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 627/3000 [06:17<23:35,  1.68epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 628/3000 [06:17<23:39,  1.67epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 628/3000 [06:17<23:39,  1.67epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 629/3000 [06:17<23:42,  1.67epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 629/3000 [06:18<23:42,  1.67epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 630/3000 [06:18<23:42,  1.67epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 630/3000 [06:19<23:42,  1.67epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 631/3000 [06:19<23:59,  1.65epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 631/3000 [06:19<23:59,  1.65epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 632/3000 [06:19<23:45,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 632/3000 [06:20<23:45,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 633/3000 [06:20<23:53,  1.65epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 633/3000 [06:21<23:53,  1.65epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 634/3000 [06:21<23:46,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 634/3000 [06:21<23:46,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 635/3000 [06:21<23:47,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 635/3000 [06:22<23:47,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 636/3000 [06:22<23:35,  1.67epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 636/3000 [06:22<23:35,  1.67epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 637/3000 [06:22<23:28,  1.68epoch/s, Training loss (per batch)=0.01]Training:  21%|██        | 637/3000 [06:23<23:28,  1.68epoch/s, Training loss (per batch)=0.01]Training:  21%|██▏       | 638/3000 [06:23<23:33,  1.67epoch/s, Training loss (per batch)=0.01]Training:  21%|██▏       | 638/3000 [06:23<23:33,  1.67epoch/s, Training loss (per batch)=0.01]Training:  21%|██▏       | 639/3000 [06:23<23:36,  1.67epoch/s, Training loss (per batch)=0.01]Training:  21%|██▏       | 639/3000 [06:24<23:36,  1.67epoch/s, Training loss (per batch)=0.01]Training:  21%|██▏       | 640/3000 [06:24<23:20,  1.69epoch/s, Training loss (per batch)=0.01]Training:  21%|██▏       | 640/3000 [06:25<23:20,  1.69epoch/s, Training loss (per batch)=0.01]Training:  21%|██▏       | 641/3000 [06:25<23:23,  1.68epoch/s, Training loss (per batch)=0.01]Training:  21%|██▏       | 641/3000 [06:25<23:23,  1.68epoch/s, Training loss (per batch)=0.01]Training:  21%|██▏       | 642/3000 [06:25<23:26,  1.68epoch/s, Training loss (per batch)=0.01]Training:  21%|██▏       | 642/3000 [06:26<23:26,  1.68epoch/s, Training loss (per batch)=0.01]Training:  21%|██▏       | 643/3000 [06:26<23:40,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██▏       | 643/3000 [06:26<23:40,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██▏       | 644/3000 [06:26<23:35,  1.66epoch/s, Training loss (per batch)=0.01]Training:  21%|██▏       | 644/3000 [06:27<23:35,  1.66epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 645/3000 [06:27<23:23,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 645/3000 [06:28<23:23,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 646/3000 [06:28<23:15,  1.69epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 646/3000 [06:28<23:15,  1.69epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 647/3000 [06:28<23:21,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 647/3000 [06:29<23:21,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 648/3000 [06:29<23:23,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 648/3000 [06:29<23:23,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 649/3000 [06:29<23:26,  1.67epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 649/3000 [06:30<23:26,  1.67epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 650/3000 [06:30<23:46,  1.65epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 650/3000 [06:31<23:46,  1.65epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 651/3000 [06:31<23:35,  1.66epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 651/3000 [06:31<23:35,  1.66epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 652/3000 [06:31<23:27,  1.67epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 652/3000 [06:32<23:27,  1.67epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 653/3000 [06:32<23:29,  1.66epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 653/3000 [06:32<23:29,  1.66epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 654/3000 [06:32<23:15,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 654/3000 [06:33<23:15,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 655/3000 [06:33<23:33,  1.66epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 655/3000 [06:34<23:33,  1.66epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 656/3000 [06:34<23:17,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 656/3000 [06:34<23:17,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 657/3000 [06:34<23:18,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 657/3000 [06:35<23:18,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 658/3000 [06:35<23:16,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 658/3000 [06:35<23:16,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 659/3000 [06:35<23:22,  1.67epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 659/3000 [06:36<23:22,  1.67epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 660/3000 [06:36<23:12,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 660/3000 [06:37<23:12,  1.68epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 661/3000 [06:37<22:56,  1.70epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 661/3000 [06:37<22:56,  1.70epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 662/3000 [06:37<22:54,  1.70epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 662/3000 [06:38<22:54,  1.70epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 663/3000 [06:38<22:58,  1.70epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 663/3000 [06:38<22:58,  1.70epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 664/3000 [06:38<22:46,  1.71epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 664/3000 [06:39<22:46,  1.71epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 665/3000 [06:39<22:44,  1.71epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 665/3000 [06:40<22:44,  1.71epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 666/3000 [06:40<22:50,  1.70epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 666/3000 [06:40<22:50,  1.70epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 667/3000 [06:40<22:52,  1.70epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 667/3000 [06:41<22:52,  1.70epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 668/3000 [06:41<22:58,  1.69epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 668/3000 [06:41<22:58,  1.69epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 669/3000 [06:41<22:45,  1.71epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 669/3000 [06:42<22:45,  1.71epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 670/3000 [06:42<22:49,  1.70epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 670/3000 [06:42<22:49,  1.70epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 671/3000 [06:42<22:43,  1.71epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 671/3000 [06:43<22:43,  1.71epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 672/3000 [06:43<22:51,  1.70epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 672/3000 [06:44<22:51,  1.70epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 673/3000 [06:44<22:53,  1.69epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 673/3000 [06:44<22:53,  1.69epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 674/3000 [06:44<22:39,  1.71epoch/s, Training loss (per batch)=0.01]Training:  22%|██▏       | 674/3000 [06:45<22:39,  1.71epoch/s, Training loss (per batch)=0.01]Training:  22%|██▎       | 675/3000 [06:45<22:54,  1.69epoch/s, Training loss (per batch)=0.01]Training:  22%|██▎       | 675/3000 [06:45<22:54,  1.69epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 676/3000 [06:45<22:39,  1.71epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 676/3000 [06:46<22:39,  1.71epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 677/3000 [06:46<22:38,  1.71epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 677/3000 [06:47<22:38,  1.71epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 678/3000 [06:47<23:01,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 678/3000 [06:47<23:01,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 679/3000 [06:47<22:41,  1.70epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 679/3000 [06:48<22:41,  1.70epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 680/3000 [06:48<22:59,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 680/3000 [06:48<22:59,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 681/3000 [06:48<22:55,  1.69epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 681/3000 [06:49<22:55,  1.69epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 682/3000 [06:49<22:55,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 682/3000 [06:50<22:55,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 683/3000 [06:50<23:00,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 683/3000 [06:50<23:00,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 684/3000 [06:50<22:55,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 684/3000 [06:51<22:55,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 685/3000 [06:51<23:03,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 685/3000 [06:51<23:03,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 686/3000 [06:51<23:07,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 686/3000 [06:52<23:07,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 687/3000 [06:52<23:11,  1.66epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 687/3000 [06:53<23:11,  1.66epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 688/3000 [06:53<23:05,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 688/3000 [06:53<23:05,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 689/3000 [06:53<22:57,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 689/3000 [06:54<22:57,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 690/3000 [06:54<23:01,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 690/3000 [06:54<23:01,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 691/3000 [06:54<22:58,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 691/3000 [06:55<22:58,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 692/3000 [06:55<23:01,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 692/3000 [06:56<23:01,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 693/3000 [06:56<23:06,  1.66epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 693/3000 [06:56<23:06,  1.66epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 694/3000 [06:56<23:07,  1.66epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 694/3000 [06:57<23:07,  1.66epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 695/3000 [06:57<23:07,  1.66epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 695/3000 [06:57<23:07,  1.66epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 696/3000 [06:57<23:03,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 696/3000 [06:58<23:03,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 697/3000 [06:58<23:05,  1.66epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 697/3000 [06:59<23:05,  1.66epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 698/3000 [06:59<22:57,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 698/3000 [06:59<22:57,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 699/3000 [06:59<22:56,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 699/3000 [07:00<22:56,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 700/3000 [07:00<23:00,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 700/3000 [07:00<23:00,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 701/3000 [07:00<22:59,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 701/3000 [07:01<22:59,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 702/3000 [07:01<22:45,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 702/3000 [07:02<22:45,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 703/3000 [07:02<22:48,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 703/3000 [07:02<22:48,  1.68epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 704/3000 [07:02<22:55,  1.67epoch/s, Training loss (per batch)=0.01]Training:  23%|██▎       | 704/3000 [07:03<22:55,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 705/3000 [07:03<22:54,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 705/3000 [07:03<22:54,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 706/3000 [07:03<22:57,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 706/3000 [07:04<22:57,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 707/3000 [07:04<22:34,  1.69epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 707/3000 [07:04<22:34,  1.69epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 708/3000 [07:05<22:15,  1.72epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 708/3000 [07:05<22:15,  1.72epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 709/3000 [07:05<22:15,  1.71epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 709/3000 [07:06<22:15,  1.71epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 710/3000 [07:06<22:17,  1.71epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 710/3000 [07:06<22:17,  1.71epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 711/3000 [07:06<22:33,  1.69epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 711/3000 [07:07<22:33,  1.69epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 712/3000 [07:07<22:26,  1.70epoch/s, Training loss (per batch)=0.01]Training:  24%|██▎       | 712/3000 [07:07<22:26,  1.70epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 713/3000 [07:07<22:39,  1.68epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 713/3000 [07:08<22:39,  1.68epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 714/3000 [07:08<22:36,  1.69epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 714/3000 [07:09<22:36,  1.69epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 715/3000 [07:09<22:48,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 715/3000 [07:09<22:48,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 716/3000 [07:09<22:58,  1.66epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 716/3000 [07:10<22:58,  1.66epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 717/3000 [07:10<23:02,  1.65epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 717/3000 [07:11<23:02,  1.65epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 718/3000 [07:11<23:01,  1.65epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 718/3000 [07:11<23:01,  1.65epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 719/3000 [07:11<23:00,  1.65epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 719/3000 [07:12<23:00,  1.65epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 720/3000 [07:12<22:46,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 720/3000 [07:12<22:46,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 721/3000 [07:12<22:56,  1.66epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 721/3000 [07:13<22:56,  1.66epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 722/3000 [07:13<22:53,  1.66epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 722/3000 [07:14<22:53,  1.66epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 723/3000 [07:14<22:54,  1.66epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 723/3000 [07:14<22:54,  1.66epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 724/3000 [07:14<22:40,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 724/3000 [07:15<22:40,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 725/3000 [07:15<22:42,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 725/3000 [07:15<22:42,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 726/3000 [07:15<22:47,  1.66epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 726/3000 [07:16<22:47,  1.66epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 727/3000 [07:16<22:22,  1.69epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 727/3000 [07:16<22:22,  1.69epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 728/3000 [07:16<22:30,  1.68epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 728/3000 [07:17<22:30,  1.68epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 729/3000 [07:17<22:34,  1.68epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 729/3000 [07:18<22:34,  1.68epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 730/3000 [07:18<22:41,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 730/3000 [07:18<22:41,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 731/3000 [07:18<22:45,  1.66epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 731/3000 [07:19<22:45,  1.66epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 732/3000 [07:19<22:35,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 732/3000 [07:19<22:35,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 733/3000 [07:19<22:34,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 733/3000 [07:20<22:34,  1.67epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 734/3000 [07:20<22:18,  1.69epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 734/3000 [07:21<22:18,  1.69epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 735/3000 [07:21<22:23,  1.69epoch/s, Training loss (per batch)=0.01]Training:  24%|██▍       | 735/3000 [07:21<22:23,  1.69epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 736/3000 [07:21<22:32,  1.67epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 736/3000 [07:22<22:32,  1.67epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 737/3000 [07:22<22:35,  1.67epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 737/3000 [07:22<22:35,  1.67epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 738/3000 [07:22<22:32,  1.67epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 738/3000 [07:23<22:32,  1.67epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 739/3000 [07:23<22:42,  1.66epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 739/3000 [07:24<22:42,  1.66epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 740/3000 [07:24<22:45,  1.65epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 740/3000 [07:24<22:45,  1.65epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 741/3000 [07:24<22:51,  1.65epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 741/3000 [07:25<22:51,  1.65epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 742/3000 [07:25<22:48,  1.65epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 742/3000 [07:25<22:48,  1.65epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 743/3000 [07:25<22:42,  1.66epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 743/3000 [07:26<22:42,  1.66epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 744/3000 [07:26<22:45,  1.65epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 744/3000 [07:27<22:45,  1.65epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 745/3000 [07:27<22:41,  1.66epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 745/3000 [07:27<22:41,  1.66epoch/s, Training loss (per batch)=0.00]Training:  25%|██▍       | 746/3000 [07:27<22:18,  1.68epoch/s, Training loss (per batch)=0.00]Training:  25%|██▍       | 746/3000 [07:28<22:18,  1.68epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 747/3000 [07:28<22:25,  1.67epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 747/3000 [07:28<22:25,  1.67epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 748/3000 [07:28<22:19,  1.68epoch/s, Training loss (per batch)=0.01]Training:  25%|██▍       | 748/3000 [07:29<22:19,  1.68epoch/s, Training loss (per batch)=0.00]Training:  25%|██▍       | 749/3000 [07:29<22:23,  1.68epoch/s, Training loss (per batch)=0.00]Training:  25%|██▍       | 749/3000 [07:30<22:23,  1.68epoch/s, Training loss (per batch)=0.01]Training:  25%|██▌       | 750/3000 [07:30<22:42,  1.65epoch/s, Training loss (per batch)=0.01]Training:  25%|██▌       | 750/3000 [07:30<22:42,  1.65epoch/s, Training loss (per batch)=0.01]Training:  25%|██▌       | 751/3000 [07:30<22:42,  1.65epoch/s, Training loss (per batch)=0.01]Training:  25%|██▌       | 751/3000 [07:31<22:42,  1.65epoch/s, Training loss (per batch)=0.01]Training:  25%|██▌       | 752/3000 [07:31<22:37,  1.66epoch/s, Training loss (per batch)=0.01]Training:  25%|██▌       | 752/3000 [07:32<22:37,  1.66epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 753/3000 [07:32<22:36,  1.66epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 753/3000 [07:32<22:36,  1.66epoch/s, Training loss (per batch)=0.01]Training:  25%|██▌       | 754/3000 [07:32<22:34,  1.66epoch/s, Training loss (per batch)=0.01]Training:  25%|██▌       | 754/3000 [07:33<22:34,  1.66epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 755/3000 [07:33<22:35,  1.66epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 755/3000 [07:33<22:35,  1.66epoch/s, Training loss (per batch)=0.01]Training:  25%|██▌       | 756/3000 [07:33<22:32,  1.66epoch/s, Training loss (per batch)=0.01]Training:  25%|██▌       | 756/3000 [07:34<22:32,  1.66epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 757/3000 [07:34<22:19,  1.67epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 757/3000 [07:35<22:19,  1.67epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 758/3000 [07:35<22:27,  1.66epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 758/3000 [07:35<22:27,  1.66epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 759/3000 [07:35<22:26,  1.66epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 759/3000 [07:36<22:26,  1.66epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 760/3000 [07:36<22:22,  1.67epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 760/3000 [07:36<22:22,  1.67epoch/s, Training loss (per batch)=0.01]Training:  25%|██▌       | 761/3000 [07:36<22:22,  1.67epoch/s, Training loss (per batch)=0.01]Training:  25%|██▌       | 761/3000 [07:37<22:22,  1.67epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 762/3000 [07:37<22:18,  1.67epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 762/3000 [07:37<22:18,  1.67epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 763/3000 [07:37<22:03,  1.69epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 763/3000 [07:38<22:03,  1.69epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 764/3000 [07:38<22:00,  1.69epoch/s, Training loss (per batch)=0.00]Training:  25%|██▌       | 764/3000 [07:39<22:00,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 765/3000 [07:39<22:07,  1.68epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 765/3000 [07:39<22:07,  1.68epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 766/3000 [07:39<22:12,  1.68epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 766/3000 [07:40<22:12,  1.68epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 767/3000 [07:40<22:09,  1.68epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 767/3000 [07:40<22:09,  1.68epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 768/3000 [07:40<21:54,  1.70epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 768/3000 [07:41<21:54,  1.70epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 769/3000 [07:41<22:01,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 769/3000 [07:42<22:01,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 770/3000 [07:42<21:52,  1.70epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 770/3000 [07:42<21:52,  1.70epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 771/3000 [07:42<21:43,  1.71epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 771/3000 [07:43<21:43,  1.71epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 772/3000 [07:43<21:43,  1.71epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 772/3000 [07:43<21:43,  1.71epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 773/3000 [07:43<22:00,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 773/3000 [07:44<22:00,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 774/3000 [07:44<21:58,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 774/3000 [07:45<21:58,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 775/3000 [07:45<21:53,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 775/3000 [07:45<21:53,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 776/3000 [07:45<22:11,  1.67epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 776/3000 [07:46<22:11,  1.67epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 777/3000 [07:46<22:17,  1.66epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 777/3000 [07:46<22:17,  1.66epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 778/3000 [07:46<22:21,  1.66epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 778/3000 [07:47<22:21,  1.66epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 779/3000 [07:47<22:29,  1.65epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 779/3000 [07:48<22:29,  1.65epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 780/3000 [07:48<22:24,  1.65epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 780/3000 [07:48<22:24,  1.65epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 781/3000 [07:48<22:13,  1.66epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 781/3000 [07:49<22:13,  1.66epoch/s, Training loss (per batch)=0.01]Training:  26%|██▌       | 782/3000 [07:49<22:20,  1.65epoch/s, Training loss (per batch)=0.01]Training:  26%|██▌       | 782/3000 [07:49<22:20,  1.65epoch/s, Training loss (per batch)=0.01]Training:  26%|██▌       | 783/3000 [07:49<22:20,  1.65epoch/s, Training loss (per batch)=0.01]Training:  26%|██▌       | 783/3000 [07:50<22:20,  1.65epoch/s, Training loss (per batch)=0.01]Training:  26%|██▌       | 784/3000 [07:50<22:01,  1.68epoch/s, Training loss (per batch)=0.01]Training:  26%|██▌       | 784/3000 [07:51<22:01,  1.68epoch/s, Training loss (per batch)=0.01]Training:  26%|██▌       | 785/3000 [07:51<21:47,  1.69epoch/s, Training loss (per batch)=0.01]Training:  26%|██▌       | 785/3000 [07:51<21:47,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 786/3000 [07:51<21:48,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 786/3000 [07:52<21:48,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 787/3000 [07:52<21:56,  1.68epoch/s, Training loss (per batch)=0.00]Training:  26%|██▌       | 787/3000 [07:52<21:56,  1.68epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 788/3000 [07:52<21:57,  1.68epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 788/3000 [07:53<21:57,  1.68epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 789/3000 [07:53<21:54,  1.68epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 789/3000 [07:54<21:54,  1.68epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 790/3000 [07:54<21:51,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 790/3000 [07:54<21:51,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 791/3000 [07:54<21:45,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 791/3000 [07:55<21:45,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 792/3000 [07:55<21:47,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 792/3000 [07:55<21:47,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 793/3000 [07:55<21:58,  1.67epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 793/3000 [07:56<21:58,  1.67epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 794/3000 [07:56<21:48,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 794/3000 [07:57<21:48,  1.69epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 795/3000 [07:57<21:57,  1.67epoch/s, Training loss (per batch)=0.00]Training:  26%|██▋       | 795/3000 [07:57<21:57,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 796/3000 [07:57<22:10,  1.66epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 796/3000 [07:58<22:10,  1.66epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 797/3000 [07:58<22:07,  1.66epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 797/3000 [07:58<22:07,  1.66epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 798/3000 [07:58<21:51,  1.68epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 798/3000 [07:59<21:51,  1.68epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 799/3000 [07:59<21:59,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 799/3000 [08:00<21:59,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 800/3000 [08:00<22:39,  1.62epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 800/3000 [08:00<22:39,  1.62epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 801/3000 [08:00<22:39,  1.62epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 801/3000 [08:01<22:39,  1.62epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 802/3000 [08:01<22:37,  1.62epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 802/3000 [08:01<22:37,  1.62epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 803/3000 [08:01<22:33,  1.62epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 803/3000 [08:02<22:33,  1.62epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 804/3000 [08:02<22:18,  1.64epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 804/3000 [08:03<22:18,  1.64epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 805/3000 [08:03<22:10,  1.65epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 805/3000 [08:03<22:10,  1.65epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 806/3000 [08:03<21:52,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 806/3000 [08:04<21:52,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 807/3000 [08:04<22:06,  1.65epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 807/3000 [08:04<22:06,  1.65epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 808/3000 [08:04<21:34,  1.69epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 808/3000 [08:05<21:34,  1.69epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 809/3000 [08:05<21:29,  1.70epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 809/3000 [08:06<21:29,  1.70epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 810/3000 [08:06<21:39,  1.68epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 810/3000 [08:06<21:39,  1.68epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 811/3000 [08:06<21:45,  1.68epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 811/3000 [08:07<21:45,  1.68epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 812/3000 [08:07<21:49,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 812/3000 [08:07<21:49,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 813/3000 [08:07<21:49,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 813/3000 [08:08<21:49,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 814/3000 [08:08<21:59,  1.66epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 814/3000 [08:09<21:59,  1.66epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 815/3000 [08:09<21:53,  1.66epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 815/3000 [08:09<21:53,  1.66epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 816/3000 [08:09<21:48,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 816/3000 [08:10<21:48,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 817/3000 [08:10<21:50,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 817/3000 [08:10<21:50,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 818/3000 [08:10<21:44,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 818/3000 [08:11<21:44,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 819/3000 [08:11<21:45,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 819/3000 [08:12<21:45,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 820/3000 [08:12<21:33,  1.69epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 820/3000 [08:12<21:33,  1.69epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 821/3000 [08:12<21:34,  1.68epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 821/3000 [08:13<21:34,  1.68epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 822/3000 [08:13<21:34,  1.68epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 822/3000 [08:13<21:34,  1.68epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 823/3000 [08:13<21:43,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 823/3000 [08:14<21:43,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 824/3000 [08:14<21:46,  1.67epoch/s, Training loss (per batch)=0.00]Training:  27%|██▋       | 824/3000 [08:15<21:46,  1.67epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 825/3000 [08:15<21:34,  1.68epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 825/3000 [08:15<21:34,  1.68epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 826/3000 [08:15<21:27,  1.69epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 826/3000 [08:16<21:27,  1.69epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 827/3000 [08:16<21:28,  1.69epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 827/3000 [08:16<21:28,  1.69epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 828/3000 [08:16<21:27,  1.69epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 828/3000 [08:17<21:27,  1.69epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 829/3000 [08:17<21:36,  1.67epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 829/3000 [08:18<21:36,  1.67epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 830/3000 [08:18<21:32,  1.68epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 830/3000 [08:18<21:32,  1.68epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 831/3000 [08:18<21:40,  1.67epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 831/3000 [08:19<21:40,  1.67epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 832/3000 [08:19<21:33,  1.68epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 832/3000 [08:19<21:33,  1.68epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 833/3000 [08:19<21:52,  1.65epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 833/3000 [08:20<21:52,  1.65epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 834/3000 [08:20<21:38,  1.67epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 834/3000 [08:21<21:38,  1.67epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 835/3000 [08:21<21:24,  1.68epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 835/3000 [08:21<21:24,  1.68epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 836/3000 [08:21<21:26,  1.68epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 836/3000 [08:22<21:26,  1.68epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 837/3000 [08:22<21:21,  1.69epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 837/3000 [08:22<21:21,  1.69epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 838/3000 [08:22<21:12,  1.70epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 838/3000 [08:23<21:12,  1.70epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 839/3000 [08:23<21:15,  1.69epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 839/3000 [08:23<21:15,  1.69epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 840/3000 [08:23<21:07,  1.70epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 840/3000 [08:24<21:07,  1.70epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 841/3000 [08:24<20:58,  1.72epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 841/3000 [08:25<20:58,  1.72epoch/s, Training loss (per batch)=0.01]Training:  28%|██▊       | 842/3000 [08:25<21:11,  1.70epoch/s, Training loss (per batch)=0.01]Training:  28%|██▊       | 842/3000 [08:25<21:11,  1.70epoch/s, Training loss (per batch)=0.01]Training:  28%|██▊       | 843/3000 [08:25<20:51,  1.72epoch/s, Training loss (per batch)=0.01]Training:  28%|██▊       | 843/3000 [08:26<20:51,  1.72epoch/s, Training loss (per batch)=0.01]Training:  28%|██▊       | 844/3000 [08:26<21:19,  1.69epoch/s, Training loss (per batch)=0.01]Training:  28%|██▊       | 844/3000 [08:26<21:19,  1.69epoch/s, Training loss (per batch)=0.01]Training:  28%|██▊       | 845/3000 [08:26<21:29,  1.67epoch/s, Training loss (per batch)=0.01]Training:  28%|██▊       | 845/3000 [08:27<21:29,  1.67epoch/s, Training loss (per batch)=0.01]Training:  28%|██▊       | 846/3000 [08:27<21:21,  1.68epoch/s, Training loss (per batch)=0.01]Training:  28%|██▊       | 846/3000 [08:28<21:21,  1.68epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 847/3000 [08:28<21:11,  1.69epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 847/3000 [08:28<21:11,  1.69epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 848/3000 [08:28<21:19,  1.68epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 848/3000 [08:29<21:19,  1.68epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 849/3000 [08:29<21:15,  1.69epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 849/3000 [08:29<21:15,  1.69epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 850/3000 [08:29<21:39,  1.65epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 850/3000 [08:30<21:39,  1.65epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 851/3000 [08:30<21:37,  1.66epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 851/3000 [08:31<21:37,  1.66epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 852/3000 [08:31<21:38,  1.65epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 852/3000 [08:31<21:38,  1.65epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 853/3000 [08:31<21:33,  1.66epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 853/3000 [08:32<21:33,  1.66epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 854/3000 [08:32<21:37,  1.65epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 854/3000 [08:32<21:37,  1.65epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 855/3000 [08:32<21:23,  1.67epoch/s, Training loss (per batch)=0.00]Training:  28%|██▊       | 855/3000 [08:33<21:23,  1.67epoch/s, Training loss (per batch)=0.00]Training:  29%|██▊       | 856/3000 [08:33<21:05,  1.69epoch/s, Training loss (per batch)=0.00]Training:  29%|██▊       | 856/3000 [08:34<21:05,  1.69epoch/s, Training loss (per batch)=0.00]Training:  29%|██▊       | 857/3000 [08:34<21:13,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▊       | 857/3000 [08:34<21:13,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▊       | 858/3000 [08:34<21:14,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▊       | 858/3000 [08:35<21:14,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▊       | 859/3000 [08:35<21:17,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▊       | 859/3000 [08:35<21:17,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▊       | 860/3000 [08:35<21:26,  1.66epoch/s, Training loss (per batch)=0.00]Training:  29%|██▊       | 860/3000 [08:36<21:26,  1.66epoch/s, Training loss (per batch)=0.00]Training:  29%|██▊       | 861/3000 [08:36<21:28,  1.66epoch/s, Training loss (per batch)=0.00]Training:  29%|██▊       | 861/3000 [08:37<21:28,  1.66epoch/s, Training loss (per batch)=0.00]Training:  29%|██▊       | 862/3000 [08:37<21:30,  1.66epoch/s, Training loss (per batch)=0.00]Training:  29%|██▊       | 862/3000 [08:37<21:30,  1.66epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 863/3000 [08:37<21:15,  1.67epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 863/3000 [08:38<21:15,  1.67epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 864/3000 [08:38<21:00,  1.70epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 864/3000 [08:38<21:00,  1.70epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 865/3000 [08:38<21:12,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 865/3000 [08:39<21:12,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 866/3000 [08:39<21:21,  1.67epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 866/3000 [08:40<21:21,  1.67epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 867/3000 [08:40<21:09,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 867/3000 [08:40<21:09,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 868/3000 [08:40<21:24,  1.66epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 868/3000 [08:41<21:24,  1.66epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 869/3000 [08:41<21:12,  1.67epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 869/3000 [08:41<21:12,  1.67epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 870/3000 [08:41<21:20,  1.66epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 870/3000 [08:42<21:20,  1.66epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 871/3000 [08:42<21:11,  1.67epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 871/3000 [08:43<21:11,  1.67epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 872/3000 [08:43<21:06,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 872/3000 [08:43<21:06,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 873/3000 [08:43<21:03,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 873/3000 [08:44<21:03,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 874/3000 [08:44<20:57,  1.69epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 874/3000 [08:44<20:57,  1.69epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 875/3000 [08:44<20:54,  1.69epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 875/3000 [08:45<20:54,  1.69epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 876/3000 [08:45<20:54,  1.69epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 876/3000 [08:46<20:54,  1.69epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 877/3000 [08:46<20:48,  1.70epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 877/3000 [08:46<20:48,  1.70epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 878/3000 [08:46<20:39,  1.71epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 878/3000 [08:47<20:39,  1.71epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 879/3000 [08:47<20:29,  1.73epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 879/3000 [08:47<20:29,  1.73epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 880/3000 [08:47<20:31,  1.72epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 880/3000 [08:48<20:31,  1.72epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 881/3000 [08:48<20:37,  1.71epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 881/3000 [08:48<20:37,  1.71epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 882/3000 [08:48<21:02,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 882/3000 [08:49<21:02,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 883/3000 [08:49<20:59,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 883/3000 [08:50<20:59,  1.68epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 884/3000 [08:50<21:10,  1.67epoch/s, Training loss (per batch)=0.00]Training:  29%|██▉       | 884/3000 [08:50<21:10,  1.67epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 885/3000 [08:50<21:11,  1.66epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 885/3000 [08:51<21:11,  1.66epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 886/3000 [08:51<21:10,  1.66epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 886/3000 [08:51<21:10,  1.66epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 887/3000 [08:51<21:13,  1.66epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 887/3000 [08:52<21:13,  1.66epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 888/3000 [08:52<21:02,  1.67epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 888/3000 [08:53<21:02,  1.67epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 889/3000 [08:53<21:00,  1.68epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 889/3000 [08:53<21:00,  1.68epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 890/3000 [08:53<21:00,  1.67epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 890/3000 [08:54<21:00,  1.67epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 891/3000 [08:54<20:54,  1.68epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 891/3000 [08:54<20:54,  1.68epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 892/3000 [08:54<20:50,  1.69epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 892/3000 [08:55<20:50,  1.69epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 893/3000 [08:55<20:42,  1.70epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 893/3000 [08:56<20:42,  1.70epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 894/3000 [08:56<20:29,  1.71epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 894/3000 [08:56<20:29,  1.71epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 895/3000 [08:56<20:19,  1.73epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 895/3000 [08:57<20:19,  1.73epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 896/3000 [08:57<20:32,  1.71epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 896/3000 [08:57<20:32,  1.71epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 897/3000 [08:57<20:42,  1.69epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 897/3000 [08:58<20:42,  1.69epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 898/3000 [08:58<20:44,  1.69epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 898/3000 [08:59<20:44,  1.69epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 899/3000 [08:59<20:38,  1.70epoch/s, Training loss (per batch)=0.00]Training:  30%|██▉       | 899/3000 [08:59<20:38,  1.70epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 900/3000 [08:59<21:02,  1.66epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 900/3000 [09:00<21:02,  1.66epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 901/3000 [09:00<21:08,  1.65epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 901/3000 [09:00<21:08,  1.65epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 902/3000 [09:00<21:12,  1.65epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 902/3000 [09:01<21:12,  1.65epoch/s, Training loss (per batch)=0.01]Training:  30%|███       | 903/3000 [09:01<21:21,  1.64epoch/s, Training loss (per batch)=0.01]Training:  30%|███       | 903/3000 [09:02<21:21,  1.64epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 904/3000 [09:02<21:23,  1.63epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 904/3000 [09:02<21:23,  1.63epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 905/3000 [09:02<21:14,  1.64epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 905/3000 [09:03<21:14,  1.64epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 906/3000 [09:03<21:19,  1.64epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 906/3000 [09:03<21:19,  1.64epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 907/3000 [09:03<21:00,  1.66epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 907/3000 [09:04<21:00,  1.66epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 908/3000 [09:04<21:06,  1.65epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 908/3000 [09:05<21:06,  1.65epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 909/3000 [09:05<20:56,  1.66epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 909/3000 [09:05<20:56,  1.66epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 910/3000 [09:05<20:49,  1.67epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 910/3000 [09:06<20:49,  1.67epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 911/3000 [09:06<20:56,  1.66epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 911/3000 [09:06<20:56,  1.66epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 912/3000 [09:06<20:52,  1.67epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 912/3000 [09:07<20:52,  1.67epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 913/3000 [09:07<20:50,  1.67epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 913/3000 [09:08<20:50,  1.67epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 914/3000 [09:08<20:43,  1.68epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 914/3000 [09:08<20:43,  1.68epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 915/3000 [09:08<20:31,  1.69epoch/s, Training loss (per batch)=0.00]Training:  30%|███       | 915/3000 [09:09<20:31,  1.69epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 916/3000 [09:09<20:23,  1.70epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 916/3000 [09:09<20:23,  1.70epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 917/3000 [09:09<20:29,  1.69epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 917/3000 [09:10<20:29,  1.69epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 918/3000 [09:10<20:45,  1.67epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 918/3000 [09:11<20:45,  1.67epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 919/3000 [09:11<20:50,  1.66epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 919/3000 [09:11<20:50,  1.66epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 920/3000 [09:11<20:44,  1.67epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 920/3000 [09:12<20:44,  1.67epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 921/3000 [09:12<20:37,  1.68epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 921/3000 [09:12<20:37,  1.68epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 922/3000 [09:12<20:34,  1.68epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 922/3000 [09:13<20:34,  1.68epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 923/3000 [09:13<20:29,  1.69epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 923/3000 [09:14<20:29,  1.69epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 924/3000 [09:14<20:13,  1.71epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 924/3000 [09:14<20:13,  1.71epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 925/3000 [09:14<20:26,  1.69epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 925/3000 [09:15<20:26,  1.69epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 926/3000 [09:15<20:10,  1.71epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 926/3000 [09:15<20:10,  1.71epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 927/3000 [09:15<20:03,  1.72epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 927/3000 [09:16<20:03,  1.72epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 928/3000 [09:16<20:13,  1.71epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 928/3000 [09:16<20:13,  1.71epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 929/3000 [09:16<20:19,  1.70epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 929/3000 [09:17<20:19,  1.70epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 930/3000 [09:17<20:25,  1.69epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 930/3000 [09:18<20:25,  1.69epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 931/3000 [09:18<20:28,  1.68epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 931/3000 [09:18<20:28,  1.68epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 932/3000 [09:18<20:35,  1.67epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 932/3000 [09:19<20:35,  1.67epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 933/3000 [09:19<20:30,  1.68epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 933/3000 [09:19<20:30,  1.68epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 934/3000 [09:19<20:32,  1.68epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 934/3000 [09:20<20:32,  1.68epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 935/3000 [09:20<20:31,  1.68epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 935/3000 [09:21<20:31,  1.68epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 936/3000 [09:21<20:34,  1.67epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 936/3000 [09:21<20:34,  1.67epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 937/3000 [09:21<20:47,  1.65epoch/s, Training loss (per batch)=0.00]Training:  31%|███       | 937/3000 [09:22<20:47,  1.65epoch/s, Training loss (per batch)=0.00]Training:  31%|███▏      | 938/3000 [09:22<20:34,  1.67epoch/s, Training loss (per batch)=0.00]Training:  31%|███▏      | 938/3000 [09:22<20:34,  1.67epoch/s, Training loss (per batch)=0.00]Training:  31%|███▏      | 939/3000 [09:22<20:41,  1.66epoch/s, Training loss (per batch)=0.00]Training:  31%|███▏      | 939/3000 [09:23<20:41,  1.66epoch/s, Training loss (per batch)=0.00]Training:  31%|███▏      | 940/3000 [09:23<20:40,  1.66epoch/s, Training loss (per batch)=0.00]Training:  31%|███▏      | 940/3000 [09:24<20:40,  1.66epoch/s, Training loss (per batch)=0.00]Training:  31%|███▏      | 941/3000 [09:24<20:31,  1.67epoch/s, Training loss (per batch)=0.00]Training:  31%|███▏      | 941/3000 [09:24<20:31,  1.67epoch/s, Training loss (per batch)=0.00]Training:  31%|███▏      | 942/3000 [09:24<20:41,  1.66epoch/s, Training loss (per batch)=0.00]Training:  31%|███▏      | 942/3000 [09:25<20:41,  1.66epoch/s, Training loss (per batch)=0.00]Training:  31%|███▏      | 943/3000 [09:25<20:40,  1.66epoch/s, Training loss (per batch)=0.00]Training:  31%|███▏      | 943/3000 [09:25<20:40,  1.66epoch/s, Training loss (per batch)=0.00]Training:  31%|███▏      | 944/3000 [09:25<20:37,  1.66epoch/s, Training loss (per batch)=0.00]Training:  31%|███▏      | 944/3000 [09:26<20:37,  1.66epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 945/3000 [09:26<20:37,  1.66epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 945/3000 [09:27<20:37,  1.66epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 946/3000 [09:27<20:30,  1.67epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 946/3000 [09:27<20:30,  1.67epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 947/3000 [09:27<20:41,  1.65epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 947/3000 [09:28<20:41,  1.65epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 948/3000 [09:28<20:27,  1.67epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 948/3000 [09:28<20:27,  1.67epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 949/3000 [09:28<20:22,  1.68epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 949/3000 [09:29<20:22,  1.68epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 950/3000 [09:29<20:34,  1.66epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 950/3000 [09:30<20:34,  1.66epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 951/3000 [09:30<20:40,  1.65epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 951/3000 [09:30<20:40,  1.65epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 952/3000 [09:30<20:46,  1.64epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 952/3000 [09:31<20:46,  1.64epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 953/3000 [09:31<20:44,  1.64epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 953/3000 [09:32<20:44,  1.64epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 954/3000 [09:32<20:43,  1.65epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 954/3000 [09:32<20:43,  1.65epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 955/3000 [09:32<20:32,  1.66epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 955/3000 [09:33<20:32,  1.66epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 956/3000 [09:33<20:34,  1.66epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 956/3000 [09:33<20:34,  1.66epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 957/3000 [09:33<20:15,  1.68epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 957/3000 [09:34<20:15,  1.68epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 958/3000 [09:34<20:07,  1.69epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 958/3000 [09:34<20:07,  1.69epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 959/3000 [09:34<19:55,  1.71epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 959/3000 [09:35<19:55,  1.71epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 960/3000 [09:35<19:52,  1.71epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 960/3000 [09:36<19:52,  1.71epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 961/3000 [09:36<20:06,  1.69epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 961/3000 [09:36<20:06,  1.69epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 962/3000 [09:36<20:05,  1.69epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 962/3000 [09:37<20:05,  1.69epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 963/3000 [09:37<19:53,  1.71epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 963/3000 [09:37<19:53,  1.71epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 964/3000 [09:37<20:08,  1.68epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 964/3000 [09:38<20:08,  1.68epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 965/3000 [09:38<20:09,  1.68epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 965/3000 [09:39<20:09,  1.68epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 966/3000 [09:39<20:02,  1.69epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 966/3000 [09:39<20:02,  1.69epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 967/3000 [09:39<19:58,  1.70epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 967/3000 [09:40<19:58,  1.70epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 968/3000 [09:40<20:08,  1.68epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 968/3000 [09:40<20:08,  1.68epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 969/3000 [09:40<20:05,  1.68epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 969/3000 [09:41<20:05,  1.68epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 970/3000 [09:41<19:51,  1.70epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 970/3000 [09:42<19:51,  1.70epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 971/3000 [09:42<19:43,  1.71epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 971/3000 [09:42<19:43,  1.71epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 972/3000 [09:42<19:46,  1.71epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 972/3000 [09:43<19:46,  1.71epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 973/3000 [09:43<19:46,  1.71epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 973/3000 [09:43<19:46,  1.71epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 974/3000 [09:43<19:42,  1.71epoch/s, Training loss (per batch)=0.00]Training:  32%|███▏      | 974/3000 [09:44<19:42,  1.71epoch/s, Training loss (per batch)=0.00]Training:  32%|███▎      | 975/3000 [09:44<19:32,  1.73epoch/s, Training loss (per batch)=0.00]Training:  32%|███▎      | 975/3000 [09:44<19:32,  1.73epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 976/3000 [09:44<19:33,  1.73epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 976/3000 [09:45<19:33,  1.73epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 977/3000 [09:45<19:56,  1.69epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 977/3000 [09:46<19:56,  1.69epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 978/3000 [09:46<20:00,  1.68epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 978/3000 [09:46<20:00,  1.68epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 979/3000 [09:46<19:41,  1.71epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 979/3000 [09:47<19:41,  1.71epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 980/3000 [09:47<19:50,  1.70epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 980/3000 [09:47<19:50,  1.70epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 981/3000 [09:47<20:01,  1.68epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 981/3000 [09:48<20:01,  1.68epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 982/3000 [09:48<20:12,  1.66epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 982/3000 [09:49<20:12,  1.66epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 983/3000 [09:49<20:05,  1.67epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 983/3000 [09:49<20:05,  1.67epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 984/3000 [09:49<20:03,  1.68epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 984/3000 [09:50<20:03,  1.68epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 985/3000 [09:50<20:12,  1.66epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 985/3000 [09:50<20:12,  1.66epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 986/3000 [09:50<20:10,  1.66epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 986/3000 [09:51<20:10,  1.66epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 987/3000 [09:51<20:18,  1.65epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 987/3000 [09:52<20:18,  1.65epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 988/3000 [09:52<20:16,  1.65epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 988/3000 [09:52<20:16,  1.65epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 989/3000 [09:52<20:19,  1.65epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 989/3000 [09:53<20:19,  1.65epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 990/3000 [09:53<20:18,  1.65epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 990/3000 [09:53<20:18,  1.65epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 991/3000 [09:53<20:03,  1.67epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 991/3000 [09:54<20:03,  1.67epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 992/3000 [09:54<20:02,  1.67epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 992/3000 [09:55<20:02,  1.67epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 993/3000 [09:55<20:02,  1.67epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 993/3000 [09:55<20:02,  1.67epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 994/3000 [09:55<20:04,  1.67epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 994/3000 [09:56<20:04,  1.67epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 995/3000 [09:56<20:05,  1.66epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 995/3000 [09:56<20:05,  1.66epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 996/3000 [09:56<20:06,  1.66epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 996/3000 [09:57<20:06,  1.66epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 997/3000 [09:57<20:08,  1.66epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 997/3000 [09:58<20:08,  1.66epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 998/3000 [09:58<19:49,  1.68epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 998/3000 [09:58<19:49,  1.68epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 999/3000 [09:58<19:57,  1.67epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 999/3000 [09:59<19:57,  1.67epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 1000/3000 [09:59<20:41,  1.61epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 1000/3000 [09:59<20:41,  1.61epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 1001/3000 [09:59<20:14,  1.65epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 1001/3000 [10:00<20:14,  1.65epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 1002/3000 [10:00<20:17,  1.64epoch/s, Training loss (per batch)=0.00]Training:  33%|███▎      | 1002/3000 [10:01<20:17,  1.64epoch/s, Training loss (per batch)=0.01]Training:  33%|███▎      | 1003/3000 [10:01<20:07,  1.65epoch/s, Training loss (per batch)=0.01]Training:  33%|███▎      | 1003/3000 [10:01<20:07,  1.65epoch/s, Training loss (per batch)=0.01]Training:  33%|███▎      | 1004/3000 [10:01<19:55,  1.67epoch/s, Training loss (per batch)=0.01]Training:  33%|███▎      | 1004/3000 [10:02<19:55,  1.67epoch/s, Training loss (per batch)=0.01]Training:  34%|███▎      | 1005/3000 [10:02<19:58,  1.67epoch/s, Training loss (per batch)=0.01]Training:  34%|███▎      | 1005/3000 [10:02<19:58,  1.67epoch/s, Training loss (per batch)=0.01]Training:  34%|███▎      | 1006/3000 [10:02<19:39,  1.69epoch/s, Training loss (per batch)=0.01]Training:  34%|███▎      | 1006/3000 [10:03<19:39,  1.69epoch/s, Training loss (per batch)=0.01]Training:  34%|███▎      | 1007/3000 [10:03<19:45,  1.68epoch/s, Training loss (per batch)=0.01]Training:  34%|███▎      | 1007/3000 [10:04<19:45,  1.68epoch/s, Training loss (per batch)=0.00]Training:  34%|███▎      | 1008/3000 [10:04<19:34,  1.70epoch/s, Training loss (per batch)=0.00]Training:  34%|███▎      | 1008/3000 [10:04<19:34,  1.70epoch/s, Training loss (per batch)=0.00]Training:  34%|███▎      | 1009/3000 [10:04<19:38,  1.69epoch/s, Training loss (per batch)=0.00]Training:  34%|███▎      | 1009/3000 [10:05<19:38,  1.69epoch/s, Training loss (per batch)=0.00]Training:  34%|███▎      | 1010/3000 [10:05<19:46,  1.68epoch/s, Training loss (per batch)=0.00]Training:  34%|███▎      | 1010/3000 [10:05<19:46,  1.68epoch/s, Training loss (per batch)=0.00]Training:  34%|███▎      | 1011/3000 [10:05<19:50,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▎      | 1011/3000 [10:06<19:50,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▎      | 1012/3000 [10:06<19:55,  1.66epoch/s, Training loss (per batch)=0.00]Training:  34%|███▎      | 1012/3000 [10:07<19:55,  1.66epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1013/3000 [10:07<19:49,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1013/3000 [10:07<19:49,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1014/3000 [10:07<19:51,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1014/3000 [10:08<19:51,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1015/3000 [10:08<19:52,  1.66epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1015/3000 [10:08<19:52,  1.66epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1016/3000 [10:08<19:50,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1016/3000 [10:09<19:50,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1017/3000 [10:09<19:49,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1017/3000 [10:10<19:49,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1018/3000 [10:10<19:48,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1018/3000 [10:10<19:48,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1019/3000 [10:10<19:39,  1.68epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1019/3000 [10:11<19:39,  1.68epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1020/3000 [10:11<19:42,  1.68epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1020/3000 [10:11<19:42,  1.68epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1021/3000 [10:11<19:40,  1.68epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1021/3000 [10:12<19:40,  1.68epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1022/3000 [10:12<19:39,  1.68epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1022/3000 [10:13<19:39,  1.68epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1023/3000 [10:13<19:39,  1.68epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1023/3000 [10:13<19:39,  1.68epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1024/3000 [10:13<19:40,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1024/3000 [10:14<19:40,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1025/3000 [10:14<19:16,  1.71epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1025/3000 [10:14<19:16,  1.71epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1026/3000 [10:14<19:12,  1.71epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1026/3000 [10:15<19:12,  1.71epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1027/3000 [10:15<19:12,  1.71epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1027/3000 [10:16<19:12,  1.71epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1028/3000 [10:16<19:29,  1.69epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1028/3000 [10:16<19:29,  1.69epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1029/3000 [10:16<19:25,  1.69epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1029/3000 [10:17<19:25,  1.69epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1030/3000 [10:17<19:38,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1030/3000 [10:17<19:38,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1031/3000 [10:17<19:32,  1.68epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1031/3000 [10:18<19:32,  1.68epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1032/3000 [10:18<19:40,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1032/3000 [10:19<19:40,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1033/3000 [10:19<19:39,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1033/3000 [10:19<19:39,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1034/3000 [10:19<19:38,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1034/3000 [10:20<19:38,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1035/3000 [10:20<19:40,  1.67epoch/s, Training loss (per batch)=0.00]Training:  34%|███▍      | 1035/3000 [10:20<19:40,  1.67epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1036/3000 [10:20<19:40,  1.66epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1036/3000 [10:21<19:40,  1.66epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1037/3000 [10:21<19:38,  1.67epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1037/3000 [10:22<19:38,  1.67epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1038/3000 [10:22<19:31,  1.67epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1038/3000 [10:22<19:31,  1.67epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1039/3000 [10:22<19:38,  1.66epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1039/3000 [10:23<19:38,  1.66epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1040/3000 [10:23<19:28,  1.68epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1040/3000 [10:23<19:28,  1.68epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1041/3000 [10:23<19:33,  1.67epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1041/3000 [10:24<19:33,  1.67epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1042/3000 [10:24<19:33,  1.67epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1042/3000 [10:25<19:33,  1.67epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1043/3000 [10:25<19:24,  1.68epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1043/3000 [10:25<19:24,  1.68epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1044/3000 [10:25<19:14,  1.69epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1044/3000 [10:26<19:14,  1.69epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1045/3000 [10:26<19:25,  1.68epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1045/3000 [10:26<19:25,  1.68epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1046/3000 [10:26<19:29,  1.67epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1046/3000 [10:27<19:29,  1.67epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1047/3000 [10:27<19:36,  1.66epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1047/3000 [10:28<19:36,  1.66epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1048/3000 [10:28<19:29,  1.67epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1048/3000 [10:28<19:29,  1.67epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1049/3000 [10:28<19:37,  1.66epoch/s, Training loss (per batch)=0.00]Training:  35%|███▍      | 1049/3000 [10:29<19:37,  1.66epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1050/3000 [10:29<19:53,  1.63epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1050/3000 [10:29<19:53,  1.63epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1051/3000 [10:29<19:44,  1.65epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1051/3000 [10:30<19:44,  1.65epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1052/3000 [10:30<19:38,  1.65epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1052/3000 [10:31<19:38,  1.65epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1053/3000 [10:31<19:37,  1.65epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1053/3000 [10:31<19:37,  1.65epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1054/3000 [10:31<19:12,  1.69epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1054/3000 [10:32<19:12,  1.69epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1055/3000 [10:32<19:18,  1.68epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1055/3000 [10:32<19:18,  1.68epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1056/3000 [10:32<19:15,  1.68epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1056/3000 [10:33<19:15,  1.68epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1057/3000 [10:33<19:24,  1.67epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1057/3000 [10:34<19:24,  1.67epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1058/3000 [10:34<19:31,  1.66epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1058/3000 [10:34<19:31,  1.66epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1059/3000 [10:34<19:36,  1.65epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1059/3000 [10:35<19:36,  1.65epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1060/3000 [10:35<19:13,  1.68epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1060/3000 [10:35<19:13,  1.68epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1061/3000 [10:35<18:59,  1.70epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1061/3000 [10:36<18:59,  1.70epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1062/3000 [10:36<19:06,  1.69epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1062/3000 [10:36<19:06,  1.69epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1063/3000 [10:36<19:08,  1.69epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1063/3000 [10:37<19:08,  1.69epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1064/3000 [10:37<19:09,  1.68epoch/s, Training loss (per batch)=0.00]Training:  35%|███▌      | 1064/3000 [10:38<19:09,  1.68epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1065/3000 [10:38<19:17,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1065/3000 [10:38<19:17,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1066/3000 [10:38<19:23,  1.66epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1066/3000 [10:39<19:23,  1.66epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1067/3000 [10:39<19:29,  1.65epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1067/3000 [10:40<19:29,  1.65epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1068/3000 [10:40<19:29,  1.65epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1068/3000 [10:40<19:29,  1.65epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1069/3000 [10:40<19:25,  1.66epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1069/3000 [10:41<19:25,  1.66epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1070/3000 [10:41<19:22,  1.66epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1070/3000 [10:41<19:22,  1.66epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1071/3000 [10:41<19:18,  1.66epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1071/3000 [10:42<19:18,  1.66epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1072/3000 [10:42<19:11,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1072/3000 [10:43<19:11,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1073/3000 [10:43<19:17,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1073/3000 [10:43<19:17,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1074/3000 [10:43<19:19,  1.66epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1074/3000 [10:44<19:19,  1.66epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1075/3000 [10:44<19:13,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1075/3000 [10:44<19:13,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1076/3000 [10:44<19:04,  1.68epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1076/3000 [10:45<19:04,  1.68epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1077/3000 [10:45<18:53,  1.70epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1077/3000 [10:45<18:53,  1.70epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1078/3000 [10:45<19:00,  1.68epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1078/3000 [10:46<19:00,  1.68epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1079/3000 [10:46<18:57,  1.69epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1079/3000 [10:47<18:57,  1.69epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1080/3000 [10:47<18:58,  1.69epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1080/3000 [10:47<18:58,  1.69epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1081/3000 [10:47<19:07,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1081/3000 [10:48<19:07,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1082/3000 [10:48<19:07,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1082/3000 [10:48<19:07,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1083/3000 [10:48<19:10,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1083/3000 [10:49<19:10,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1084/3000 [10:49<19:17,  1.66epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1084/3000 [10:50<19:17,  1.66epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1085/3000 [10:50<19:18,  1.65epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1085/3000 [10:50<19:18,  1.65epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1086/3000 [10:50<19:03,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1086/3000 [10:51<19:03,  1.67epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1087/3000 [10:51<19:25,  1.64epoch/s, Training loss (per batch)=0.00]Training:  36%|███▌      | 1087/3000 [10:52<19:25,  1.64epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1088/3000 [10:52<19:23,  1.64epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1088/3000 [10:52<19:23,  1.64epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1089/3000 [10:52<19:19,  1.65epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1089/3000 [10:53<19:19,  1.65epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1090/3000 [10:53<19:15,  1.65epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1090/3000 [10:53<19:15,  1.65epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1091/3000 [10:53<19:14,  1.65epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1091/3000 [10:54<19:14,  1.65epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1092/3000 [10:54<19:26,  1.64epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1092/3000 [10:55<19:26,  1.64epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1093/3000 [10:55<19:20,  1.64epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1093/3000 [10:55<19:20,  1.64epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1094/3000 [10:55<19:13,  1.65epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1094/3000 [10:56<19:13,  1.65epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1095/3000 [10:56<19:18,  1.64epoch/s, Training loss (per batch)=0.00]Training:  36%|███▋      | 1095/3000 [10:56<19:18,  1.64epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1096/3000 [10:56<19:13,  1.65epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1096/3000 [10:57<19:13,  1.65epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1097/3000 [10:57<19:01,  1.67epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1097/3000 [10:58<19:01,  1.67epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1098/3000 [10:58<19:04,  1.66epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1098/3000 [10:58<19:04,  1.66epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1099/3000 [10:58<19:06,  1.66epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1099/3000 [10:59<19:06,  1.66epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1100/3000 [10:59<19:19,  1.64epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1100/3000 [10:59<19:19,  1.64epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1101/3000 [10:59<19:26,  1.63epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1101/3000 [11:00<19:26,  1.63epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1102/3000 [11:00<19:19,  1.64epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1102/3000 [11:01<19:19,  1.64epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1103/3000 [11:01<18:56,  1.67epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1103/3000 [11:01<18:56,  1.67epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1104/3000 [11:01<18:55,  1.67epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1104/3000 [11:02<18:55,  1.67epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1105/3000 [11:02<18:39,  1.69epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1105/3000 [11:02<18:39,  1.69epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1106/3000 [11:02<18:27,  1.71epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1106/3000 [11:03<18:27,  1.71epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1107/3000 [11:03<18:30,  1.71epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1107/3000 [11:04<18:30,  1.71epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1108/3000 [11:04<18:37,  1.69epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1108/3000 [11:04<18:37,  1.69epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1109/3000 [11:04<18:31,  1.70epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1109/3000 [11:05<18:31,  1.70epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1110/3000 [11:05<18:26,  1.71epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1110/3000 [11:05<18:26,  1.71epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1111/3000 [11:05<18:22,  1.71epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1111/3000 [11:06<18:22,  1.71epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1112/3000 [11:06<18:20,  1.72epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1112/3000 [11:06<18:20,  1.72epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1113/3000 [11:06<18:13,  1.73epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1113/3000 [11:07<18:13,  1.73epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1114/3000 [11:07<18:11,  1.73epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1114/3000 [11:08<18:11,  1.73epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1115/3000 [11:08<18:19,  1.71epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1115/3000 [11:08<18:19,  1.71epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1116/3000 [11:08<18:25,  1.70epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1116/3000 [11:09<18:25,  1.70epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1117/3000 [11:09<18:31,  1.69epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1117/3000 [11:09<18:31,  1.69epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1118/3000 [11:09<18:40,  1.68epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1118/3000 [11:10<18:40,  1.68epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1119/3000 [11:10<18:37,  1.68epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1119/3000 [11:11<18:37,  1.68epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1120/3000 [11:11<18:44,  1.67epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1120/3000 [11:11<18:44,  1.67epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1121/3000 [11:11<18:42,  1.67epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1121/3000 [11:12<18:42,  1.67epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1122/3000 [11:12<18:32,  1.69epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1122/3000 [11:12<18:32,  1.69epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1123/3000 [11:12<18:29,  1.69epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1123/3000 [11:13<18:29,  1.69epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1124/3000 [11:13<18:28,  1.69epoch/s, Training loss (per batch)=0.00]Training:  37%|███▋      | 1124/3000 [11:14<18:28,  1.69epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1125/3000 [11:14<18:31,  1.69epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1125/3000 [11:14<18:31,  1.69epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1126/3000 [11:14<18:33,  1.68epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1126/3000 [11:15<18:33,  1.68epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1127/3000 [11:15<18:27,  1.69epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1127/3000 [11:15<18:27,  1.69epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1128/3000 [11:15<18:35,  1.68epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1128/3000 [11:16<18:35,  1.68epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1129/3000 [11:16<18:38,  1.67epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1129/3000 [11:17<18:38,  1.67epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1130/3000 [11:17<18:28,  1.69epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1130/3000 [11:17<18:28,  1.69epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1131/3000 [11:17<18:34,  1.68epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1131/3000 [11:18<18:34,  1.68epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1132/3000 [11:18<18:39,  1.67epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1132/3000 [11:18<18:39,  1.67epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1133/3000 [11:18<18:55,  1.64epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1133/3000 [11:19<18:55,  1.64epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1134/3000 [11:19<18:53,  1.65epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1134/3000 [11:20<18:53,  1.65epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1135/3000 [11:20<18:45,  1.66epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1135/3000 [11:20<18:45,  1.66epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1136/3000 [11:20<18:44,  1.66epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1136/3000 [11:21<18:44,  1.66epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1137/3000 [11:21<18:49,  1.65epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1137/3000 [11:21<18:49,  1.65epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1138/3000 [11:21<18:58,  1.64epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1138/3000 [11:22<18:58,  1.64epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1139/3000 [11:22<18:44,  1.66epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1139/3000 [11:23<18:44,  1.66epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1140/3000 [11:23<18:42,  1.66epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1140/3000 [11:23<18:42,  1.66epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1141/3000 [11:23<18:49,  1.65epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1141/3000 [11:24<18:49,  1.65epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1142/3000 [11:24<18:49,  1.65epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1142/3000 [11:24<18:49,  1.65epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1143/3000 [11:24<18:22,  1.68epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1143/3000 [11:25<18:22,  1.68epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1144/3000 [11:25<18:25,  1.68epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1144/3000 [11:26<18:25,  1.68epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1145/3000 [11:26<18:23,  1.68epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1145/3000 [11:26<18:23,  1.68epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1146/3000 [11:26<18:29,  1.67epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1146/3000 [11:27<18:29,  1.67epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1147/3000 [11:27<18:19,  1.68epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1147/3000 [11:27<18:19,  1.68epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1148/3000 [11:27<18:26,  1.67epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1148/3000 [11:28<18:26,  1.67epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1149/3000 [11:28<18:29,  1.67epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1149/3000 [11:29<18:29,  1.67epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1150/3000 [11:29<18:50,  1.64epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1150/3000 [11:29<18:50,  1.64epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1151/3000 [11:29<18:44,  1.64epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1151/3000 [11:30<18:44,  1.64epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1152/3000 [11:30<18:39,  1.65epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1152/3000 [11:30<18:39,  1.65epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1153/3000 [11:30<18:48,  1.64epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1153/3000 [11:31<18:48,  1.64epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1154/3000 [11:31<18:44,  1.64epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1154/3000 [11:32<18:44,  1.64epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1155/3000 [11:32<18:31,  1.66epoch/s, Training loss (per batch)=0.00]Training:  38%|███▊      | 1155/3000 [11:32<18:31,  1.66epoch/s, Training loss (per batch)=0.00]Training:  39%|███▊      | 1156/3000 [11:32<18:35,  1.65epoch/s, Training loss (per batch)=0.00]Training:  39%|███▊      | 1156/3000 [11:33<18:35,  1.65epoch/s, Training loss (per batch)=0.00]Training:  39%|███▊      | 1157/3000 [11:33<18:19,  1.68epoch/s, Training loss (per batch)=0.00]Training:  39%|███▊      | 1157/3000 [11:33<18:19,  1.68epoch/s, Training loss (per batch)=0.00]Training:  39%|███▊      | 1158/3000 [11:33<18:29,  1.66epoch/s, Training loss (per batch)=0.00]Training:  39%|███▊      | 1158/3000 [11:34<18:29,  1.66epoch/s, Training loss (per batch)=0.00]Training:  39%|███▊      | 1159/3000 [11:34<18:24,  1.67epoch/s, Training loss (per batch)=0.00]Training:  39%|███▊      | 1159/3000 [11:35<18:24,  1.67epoch/s, Training loss (per batch)=0.00]Training:  39%|███▊      | 1160/3000 [11:35<18:17,  1.68epoch/s, Training loss (per batch)=0.00]Training:  39%|███▊      | 1160/3000 [11:35<18:17,  1.68epoch/s, Training loss (per batch)=0.00]Training:  39%|███▊      | 1161/3000 [11:35<18:13,  1.68epoch/s, Training loss (per batch)=0.00]Training:  39%|███▊      | 1161/3000 [11:36<18:13,  1.68epoch/s, Training loss (per batch)=0.00]Training:  39%|███▊      | 1162/3000 [11:36<17:57,  1.71epoch/s, Training loss (per batch)=0.00]Training:  39%|███▊      | 1162/3000 [11:36<17:57,  1.71epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1163/3000 [11:36<18:02,  1.70epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1163/3000 [11:37<18:02,  1.70epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1164/3000 [11:37<18:12,  1.68epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1164/3000 [11:38<18:12,  1.68epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1165/3000 [11:38<18:14,  1.68epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1165/3000 [11:38<18:14,  1.68epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1166/3000 [11:38<18:17,  1.67epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1166/3000 [11:39<18:17,  1.67epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1167/3000 [11:39<18:23,  1.66epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1167/3000 [11:39<18:23,  1.66epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1168/3000 [11:39<18:29,  1.65epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1168/3000 [11:40<18:29,  1.65epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1169/3000 [11:40<18:29,  1.65epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1169/3000 [11:41<18:29,  1.65epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1170/3000 [11:41<18:24,  1.66epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1170/3000 [11:41<18:24,  1.66epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1171/3000 [11:41<18:26,  1.65epoch/s, Training loss (per batch)=0.01]Training:  39%|███▉      | 1171/3000 [11:42<18:26,  1.65epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1172/3000 [11:42<18:27,  1.65epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1172/3000 [11:42<18:27,  1.65epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1173/3000 [11:42<18:26,  1.65epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1173/3000 [11:43<18:26,  1.65epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1174/3000 [11:43<18:33,  1.64epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1174/3000 [11:44<18:33,  1.64epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1175/3000 [11:44<18:12,  1.67epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1175/3000 [11:44<18:12,  1.67epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1176/3000 [11:44<18:06,  1.68epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1176/3000 [11:45<18:06,  1.68epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1177/3000 [11:45<18:10,  1.67epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1177/3000 [11:45<18:10,  1.67epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1178/3000 [11:45<18:16,  1.66epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1178/3000 [11:46<18:16,  1.66epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1179/3000 [11:46<18:16,  1.66epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1179/3000 [11:47<18:16,  1.66epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1180/3000 [11:47<18:17,  1.66epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1180/3000 [11:47<18:17,  1.66epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1181/3000 [11:47<18:27,  1.64epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1181/3000 [11:48<18:27,  1.64epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1182/3000 [11:48<18:10,  1.67epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1182/3000 [11:48<18:10,  1.67epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1183/3000 [11:48<18:12,  1.66epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1183/3000 [11:49<18:12,  1.66epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1184/3000 [11:49<18:11,  1.66epoch/s, Training loss (per batch)=0.00]Training:  39%|███▉      | 1184/3000 [11:50<18:11,  1.66epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1185/3000 [11:50<17:53,  1.69epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1185/3000 [11:50<17:53,  1.69epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1186/3000 [11:50<17:50,  1.69epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1186/3000 [11:51<17:50,  1.69epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1187/3000 [11:51<17:49,  1.70epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1187/3000 [11:51<17:49,  1.70epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1188/3000 [11:51<17:55,  1.69epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1188/3000 [11:52<17:55,  1.69epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1189/3000 [11:52<18:06,  1.67epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1189/3000 [11:53<18:06,  1.67epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1190/3000 [11:53<18:07,  1.66epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1190/3000 [11:53<18:07,  1.66epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1191/3000 [11:53<18:07,  1.66epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1191/3000 [11:54<18:07,  1.66epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1192/3000 [11:54<18:11,  1.66epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1192/3000 [11:54<18:11,  1.66epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1193/3000 [11:54<18:00,  1.67epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1193/3000 [11:55<18:00,  1.67epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1194/3000 [11:55<17:56,  1.68epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1194/3000 [11:56<17:56,  1.68epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1195/3000 [11:56<17:52,  1.68epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1195/3000 [11:56<17:52,  1.68epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1196/3000 [11:56<17:53,  1.68epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1196/3000 [11:57<17:53,  1.68epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1197/3000 [11:57<17:56,  1.67epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1197/3000 [11:57<17:56,  1.67epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1198/3000 [11:57<17:54,  1.68epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1198/3000 [11:58<17:54,  1.68epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1199/3000 [11:58<17:54,  1.68epoch/s, Training loss (per batch)=0.00]Training:  40%|███▉      | 1199/3000 [11:59<17:54,  1.68epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1200/3000 [11:59<18:43,  1.60epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1200/3000 [11:59<18:43,  1.60epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1201/3000 [11:59<18:26,  1.63epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1201/3000 [12:00<18:26,  1.63epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1202/3000 [12:00<18:11,  1.65epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1202/3000 [12:00<18:11,  1.65epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1203/3000 [12:00<18:07,  1.65epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1203/3000 [12:01<18:07,  1.65epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1204/3000 [12:01<17:51,  1.68epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1204/3000 [12:02<17:51,  1.68epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1205/3000 [12:02<18:00,  1.66epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1205/3000 [12:02<18:00,  1.66epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1206/3000 [12:02<17:53,  1.67epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1206/3000 [12:03<17:53,  1.67epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1207/3000 [12:03<17:56,  1.67epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1207/3000 [12:03<17:56,  1.67epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1208/3000 [12:03<18:01,  1.66epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1208/3000 [12:04<18:01,  1.66epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1209/3000 [12:04<18:02,  1.65epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1209/3000 [12:05<18:02,  1.65epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1210/3000 [12:05<18:01,  1.66epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1210/3000 [12:05<18:01,  1.66epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1211/3000 [12:05<18:08,  1.64epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1211/3000 [12:06<18:08,  1.64epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1212/3000 [12:06<18:09,  1.64epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1212/3000 [12:06<18:09,  1.64epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1213/3000 [12:06<18:10,  1.64epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1213/3000 [12:07<18:10,  1.64epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1214/3000 [12:07<18:18,  1.63epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1214/3000 [12:08<18:18,  1.63epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1215/3000 [12:08<18:05,  1.64epoch/s, Training loss (per batch)=0.00]Training:  40%|████      | 1215/3000 [12:08<18:05,  1.64epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1216/3000 [12:08<17:45,  1.67epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1216/3000 [12:09<17:45,  1.67epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1217/3000 [12:09<17:26,  1.70epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1217/3000 [12:09<17:26,  1.70epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1218/3000 [12:09<17:39,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1218/3000 [12:10<17:39,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1219/3000 [12:10<17:44,  1.67epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1219/3000 [12:11<17:44,  1.67epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1220/3000 [12:11<17:41,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1220/3000 [12:11<17:41,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1221/3000 [12:11<17:44,  1.67epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1221/3000 [12:12<17:44,  1.67epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1222/3000 [12:12<17:35,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1222/3000 [12:12<17:35,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1223/3000 [12:12<17:40,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1223/3000 [12:13<17:40,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1224/3000 [12:13<17:48,  1.66epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1224/3000 [12:14<17:48,  1.66epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1225/3000 [12:14<17:52,  1.65epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1225/3000 [12:14<17:52,  1.65epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1226/3000 [12:14<17:33,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1226/3000 [12:15<17:33,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1227/3000 [12:15<17:23,  1.70epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1227/3000 [12:15<17:23,  1.70epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1228/3000 [12:15<17:40,  1.67epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1228/3000 [12:16<17:40,  1.67epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1229/3000 [12:16<17:51,  1.65epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1229/3000 [12:17<17:51,  1.65epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1230/3000 [12:17<17:51,  1.65epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1230/3000 [12:17<17:51,  1.65epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1231/3000 [12:17<17:42,  1.66epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1231/3000 [12:18<17:42,  1.66epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1232/3000 [12:18<17:45,  1.66epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1232/3000 [12:18<17:45,  1.66epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1233/3000 [12:18<17:37,  1.67epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1233/3000 [12:19<17:37,  1.67epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1234/3000 [12:19<17:31,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1234/3000 [12:20<17:31,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1235/3000 [12:20<17:46,  1.66epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1235/3000 [12:20<17:46,  1.66epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1236/3000 [12:20<17:43,  1.66epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1236/3000 [12:21<17:43,  1.66epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1237/3000 [12:21<17:28,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████      | 1237/3000 [12:21<17:28,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████▏     | 1238/3000 [12:21<17:31,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████▏     | 1238/3000 [12:22<17:31,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████▏     | 1239/3000 [12:22<17:18,  1.70epoch/s, Training loss (per batch)=0.00]Training:  41%|████▏     | 1239/3000 [12:23<17:18,  1.70epoch/s, Training loss (per batch)=0.00]Training:  41%|████▏     | 1240/3000 [12:23<17:04,  1.72epoch/s, Training loss (per batch)=0.00]Training:  41%|████▏     | 1240/3000 [12:23<17:04,  1.72epoch/s, Training loss (per batch)=0.00]Training:  41%|████▏     | 1241/3000 [12:23<17:13,  1.70epoch/s, Training loss (per batch)=0.00]Training:  41%|████▏     | 1241/3000 [12:24<17:13,  1.70epoch/s, Training loss (per batch)=0.00]Training:  41%|████▏     | 1242/3000 [12:24<17:20,  1.69epoch/s, Training loss (per batch)=0.00]Training:  41%|████▏     | 1242/3000 [12:24<17:20,  1.69epoch/s, Training loss (per batch)=0.00]Training:  41%|████▏     | 1243/3000 [12:24<17:27,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████▏     | 1243/3000 [12:25<17:27,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████▏     | 1244/3000 [12:25<17:28,  1.68epoch/s, Training loss (per batch)=0.00]Training:  41%|████▏     | 1244/3000 [12:26<17:28,  1.68epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1245/3000 [12:26<17:20,  1.69epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1245/3000 [12:26<17:20,  1.69epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1246/3000 [12:26<17:34,  1.66epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1246/3000 [12:27<17:34,  1.66epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1247/3000 [12:27<17:37,  1.66epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1247/3000 [12:27<17:37,  1.66epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1248/3000 [12:27<17:41,  1.65epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1248/3000 [12:28<17:41,  1.65epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1249/3000 [12:28<17:38,  1.65epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1249/3000 [12:29<17:38,  1.65epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1250/3000 [12:29<17:43,  1.65epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1250/3000 [12:29<17:43,  1.65epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1251/3000 [12:29<17:39,  1.65epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1251/3000 [12:30<17:39,  1.65epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1252/3000 [12:30<17:39,  1.65epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1252/3000 [12:30<17:39,  1.65epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1253/3000 [12:30<17:48,  1.63epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1253/3000 [12:31<17:48,  1.63epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1254/3000 [12:31<17:36,  1.65epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1254/3000 [12:32<17:36,  1.65epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1255/3000 [12:32<17:22,  1.67epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1255/3000 [12:32<17:22,  1.67epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1256/3000 [12:32<17:11,  1.69epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1256/3000 [12:33<17:11,  1.69epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1257/3000 [12:33<17:11,  1.69epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1257/3000 [12:33<17:11,  1.69epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1258/3000 [12:33<17:05,  1.70epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1258/3000 [12:34<17:05,  1.70epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1259/3000 [12:34<17:00,  1.71epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1259/3000 [12:35<17:00,  1.71epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1260/3000 [12:35<16:59,  1.71epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1260/3000 [12:35<16:59,  1.71epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1261/3000 [12:35<16:56,  1.71epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1261/3000 [12:36<16:56,  1.71epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1262/3000 [12:36<17:02,  1.70epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1262/3000 [12:36<17:02,  1.70epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1263/3000 [12:36<17:12,  1.68epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1263/3000 [12:37<17:12,  1.68epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1264/3000 [12:37<17:01,  1.70epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1264/3000 [12:37<17:01,  1.70epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1265/3000 [12:37<17:05,  1.69epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1265/3000 [12:38<17:05,  1.69epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1266/3000 [12:38<17:10,  1.68epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1266/3000 [12:39<17:10,  1.68epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1267/3000 [12:39<17:13,  1.68epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1267/3000 [12:39<17:13,  1.68epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1268/3000 [12:39<17:09,  1.68epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1268/3000 [12:40<17:09,  1.68epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1269/3000 [12:40<17:12,  1.68epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1269/3000 [12:40<17:12,  1.68epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1270/3000 [12:40<17:01,  1.69epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1270/3000 [12:41<17:01,  1.69epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1271/3000 [12:41<17:13,  1.67epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1271/3000 [12:42<17:13,  1.67epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1272/3000 [12:42<17:14,  1.67epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1272/3000 [12:42<17:14,  1.67epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1273/3000 [12:42<17:03,  1.69epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1273/3000 [12:43<17:03,  1.69epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1274/3000 [12:43<16:54,  1.70epoch/s, Training loss (per batch)=0.00]Training:  42%|████▏     | 1274/3000 [12:43<16:54,  1.70epoch/s, Training loss (per batch)=0.00]Training:  42%|████▎     | 1275/3000 [12:43<17:01,  1.69epoch/s, Training loss (per batch)=0.00]Training:  42%|████▎     | 1275/3000 [12:44<17:01,  1.69epoch/s, Training loss (per batch)=0.00]Training:  43%|████▎     | 1276/3000 [12:44<17:02,  1.69epoch/s, Training loss (per batch)=0.00]Training:  43%|████▎     | 1276/3000 [12:45<17:02,  1.69epoch/s, Training loss (per batch)=0.00]Training:  43%|████▎     | 1277/3000 [12:45<17:04,  1.68epoch/s, Training loss (per batch)=0.00]Training:  43%|████▎     | 1277/3000 [12:45<17:04,  1.68epoch/s, Training loss (per batch)=0.00]Training:  43%|████▎     | 1278/3000 [12:45<16:56,  1.69epoch/s, Training loss (per batch)=0.00]Training:  43%|████▎     | 1278/3000 [12:46<16:56,  1.69epoch/s, Training loss (per batch)=0.00]Training:  43%|████▎     | 1279/3000 [12:46<16:54,  1.70epoch/s, Training loss (per batch)=0.00]Training:  43%|████▎     | 1279/3000 [12:46<16:54,  1.70epoch/s, Training loss (per batch)=0.00]Training:  43%|████▎     | 1280/3000 [12:46<16:56,  1.69epoch/s, Training loss (per batch)=0.00]Training:  43%|████▎     | 1280/3000 [12:47<16:56,  1.69epoch/s, Training loss (per batch)=0.00]Training:  43%|████▎     | 1281/3000 [12:47<16:42,  1.71epoch/s, Training loss (per batch)=0.00]